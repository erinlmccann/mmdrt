{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "580a16cc-bef3-4022-9635-09778fd4d5aa",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Telemetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a658ea0-9e31-45e3-a0d5-28506df3bfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import datetime\n",
    "import re\n",
    "from typing import Union, List, Tuple\n",
    "\n",
    "import duckdb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e6e4cf9-bdda-492b-a706-cab1d4da123f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_parquet(file_path: str,\n",
    "                   output_directory: str):\n",
    "    \"\"\"Convert CSV files to Parquet file format.\"\"\"\n",
    "\n",
    "    # create output file name\n",
    "    output_parquet_file = os.path.join(output_directory, f\"{os.path.splitext(os.path.basename(file_path))[0]}.parquet\")\n",
    "    \n",
    "    # construct query to convert to parquet files\n",
    "    sql = f\"\"\"\n",
    "    COPY(\n",
    "        SELECT\n",
    "            *\n",
    "        FROM \n",
    "            '{file_path}'\n",
    "        ) TO '{output_parquet_file}' (FORMAT PARQUET);\n",
    "    \"\"\"\n",
    "    \n",
    "    # execute conversion\n",
    "    duckdb.query(sql)\n",
    "    \n",
    "    return output_parquet_file\n",
    "\n",
    "\n",
    "def read_tagging_file(tagging_file: str) -> pd.DataFrame:\n",
    "    \"\"\"Read in raw excel tagging file to data frame and add field for PST date time fields.\"\"\"\n",
    "    \n",
    "    # read in tagging data\n",
    "    df = pd.read_excel(tagging_file)\n",
    "\n",
    "    # rename fields\n",
    "    df.rename(columns={\"rel_datetime\": \"tag_release_date\"}, inplace=True)\n",
    "\n",
    "    # adjust date times in tagging file to PST\n",
    "    df[\"tag_activation_date_pst\"] = pd.to_datetime(df[\"tag_activation_date\"]) - pd.Timedelta(hours=1)\n",
    "    df[\"tag_release_date_pst\"] = pd.to_datetime(df[\"tag_release_date\"]) - pd.Timedelta(hours=1)\n",
    "    \n",
    "    return df.sort_values(by=\"fish_id\").reset_index(drop=True)\n",
    "\n",
    "\n",
    "def read_beacon_file(beacon_file: str) -> pd.DataFrame:\n",
    "    \"\"\"Read in raw beacon file to data frame.\"\"\"\n",
    "    \n",
    "    pass\n",
    "\n",
    "\n",
    "def generate_directory_list(target_directory: str,\n",
    "                            ignore_dirs: Tuple[str] = (\".DS_Store\", \"pre_study\", \"zips\", \".zip\")) -> list:\n",
    "    \"\"\"Generate a clearn directory list.\"\"\"\n",
    "    \n",
    "    return [os.path.join(target_directory, i) for i in os.listdir(target_directory) if i not in ignore_dirs]\n",
    "\n",
    "\n",
    "def add_trailing_zeros(x: str, \n",
    "                       length: int):\n",
    "    \"\"\"Add trailing zeros to a string.\"\"\"\n",
    "    \n",
    "    return(x + f\"{'0' * (length - len(x))}\")\n",
    "\n",
    "\n",
    "def add_leading_zeros(x: str, \n",
    "                    length: int):\n",
    "    \"\"\"Add leading zeros to a string.\"\"\"\n",
    "    \n",
    "    return(f\"{'0' * (length - len(x))}\" + x)\n",
    "\n",
    "\n",
    "def validate_file_to_directory_match(file_list: list):\n",
    "    \"\"\"Validate file names to their parent directory to ensure that no errors have occurred.\"\"\"\n",
    "\n",
    "    valid_list = []\n",
    "    \n",
    "    for i in file_list:\n",
    "\n",
    "        # get the source directory name of the download\n",
    "        source_directory = os.path.basename(os.path.dirname(i))\n",
    "\n",
    "        # extact the file parts to match to source directory\n",
    "        target_file_parts = os.path.splitext(os.path.basename(i))\n",
    "        target_file_base = target_file_parts[0].split(\"_\")[-1]\n",
    "        target_file_extension = target_file_parts[1]\n",
    "\n",
    "        if source_directory != target_file_base:\n",
    "            print(f\"File '{i}' does not match the parent directory name.\")\n",
    "            print(\"Removing from inputs.  Please review.\")\n",
    "\n",
    "        else:\n",
    "            valid_list.append(i)\n",
    "\n",
    "    return valid_list\n",
    "\n",
    "\n",
    "def generate_orion_import_file_list(orion_dir: str):\n",
    "    \"\"\"Generate a list of orion files to import after validation.\"\"\"\n",
    "\n",
    "    # generate full path lists of text and hex files in the orion directory\n",
    "    text_files = glob.glob(os.path.join(orion_dir, \"**/*.txt\"))\n",
    "    hex_files = glob.glob(os.path.join(orion_dir, \"**/*.hex\"))\n",
    "\n",
    "    # validate file name to directory name match\n",
    "    text_files = validate_file_to_directory_match(text_files)\n",
    "    hex_files = validate_file_to_directory_match(hex_files)\n",
    "\n",
    "    # validate to ensure a hex / text pair\n",
    "    text_file_base_list = [os.path.splitext(os.path.basename(i))[0] for i in text_files]\n",
    "    hex_file_base_list = [os.path.splitext(os.path.basename(i))[0] for i in hex_files]\n",
    "\n",
    "    # files in text list not in hex list\n",
    "    no_match_text_files = set(text_file_base_list) - set(hex_file_base_list)\n",
    "\n",
    "    # files in hex list not in text list\n",
    "    no_match_hex_files = set(hex_file_base_list) - set(text_file_base_list)\n",
    "\n",
    "    if len(no_match_text_files) > 0:\n",
    "        print(f\"There are not hex file matches for the following text files: {no_match_text_files}\")\n",
    "\n",
    "    if len(no_match_hex_files) > 0:\n",
    "        print(f\"There are not text file matches for the following hex files: {no_match_hex_files}\")\n",
    "\n",
    "    # hex file size should be smaller than the text file or something may be wrong\n",
    "    text_file_sizes = [os.stat(i).st_size for i in text_files]\n",
    "    hex_file_sizes = [os.stat(i).st_size for i in hex_files]\n",
    "\n",
    "    for index, i in enumerate(text_files):\n",
    "        \n",
    "        text_file_size = os.stat(i).st_size\n",
    "        hex_file_size = os.stat(f\"{os.path.splitext(i)[0]}.hex\").st_size\n",
    "\n",
    "        if hex_file_size >= text_file_size:\n",
    "            print(f\"WARNING:  Text file '{i}' is smaller than or equal to the hex file size (bytes).\")\n",
    "            print(f\"Text file size: {text_file_size}, Hex file size: {hex_file_size}, Difference (hex - text): {hex_file_size - text_file_size}\")\n",
    "            print(f\"Removing files from import.  Please review.\")\n",
    "\n",
    "            # remove files with incorrect sizes\n",
    "            text_files.remove(text_files[index])\n",
    "            \n",
    "    return text_files\n",
    "\n",
    "\n",
    "def whitespace_to_csv(input_file:str, \n",
    "                      output_dir:str) -> str:\n",
    "    \"\"\"Generate new output files with whitespace converted to CSV.\"\"\"\n",
    "    \n",
    "    # extract basename from input file\n",
    "    basename = os.path.splitext(os.path.basename(input_file))[0]\n",
    "    \n",
    "    # construct output file name\n",
    "    output_file = os.path.join(output_dir, f\"{basename}.csv\")\n",
    "    \n",
    "    # open file to write\n",
    "    with open(output_file, \"w\") as out:\n",
    "        \n",
    "        # read input file as string\n",
    "        with open(input_file) as get:\n",
    "            content = get.read()\n",
    "            \n",
    "            # write content replacing any whitespace with commas but keeping new lines or carriage returns\n",
    "            out.write(re.sub(\"[^\\S^\\r\\n]+\", \",\", content))\n",
    "            \n",
    "    return output_file\n",
    "\n",
    "\n",
    "def orion_raw_to_parquet(input_file: str,\n",
    "                         output_directory: str,\n",
    "                         target_frequency_list: list,\n",
    "                         target_code_list: list) -> str:\n",
    "    \"\"\"Create a parquet file for each formatted CSV.\"\"\"\n",
    "    \n",
    "    # extract file name from input file\n",
    "    file_name = f\"0_ORION_{os.path.splitext(os.path.basename(input_file))[0]}\"\n",
    "    \n",
    "    # create output file name\n",
    "    output_parquet_file = os.path.join(output_directory, f\"{file_name}.parquet\")\n",
    "\n",
    "\n",
    "    sql = f\"\"\"\n",
    "    COPY(\n",
    "        SELECT\n",
    "            concat(\n",
    "                CASE\n",
    "                    WHEN length(Freq::VARCHAR) = 4\n",
    "                    THEN Freq::VARCHAR || '000'\n",
    "                    WHEN length(Freq::VARCHAR) = 5\n",
    "                    THEN Freq::VARCHAR || '00'        \n",
    "                    WHEN length(Freq::VARCHAR) = 6\n",
    "                    THEN Freq::VARCHAR || '0' \n",
    "                    ELSE Freq::VARCHAR \n",
    "                END\n",
    "                ,'.'\n",
    "                ,CASE\n",
    "                    WHEN length(Code::VARCHAR) = 1\n",
    "                    THEN '00' || Code::VARCHAR\n",
    "                    WHEN length(Code::VARCHAR) = 2\n",
    "                    THEN '0' || Code::VARCHAR  \n",
    "                    ELSE Code::VARCHAR\n",
    "                END\n",
    "            ) AS fish_id\n",
    "            ,(Date + Time) AS date_time\n",
    "            ,Site AS receiver_id\n",
    "            ,Power AS signal_power\n",
    "            ,'{file_name}' AS file_nm\n",
    "        FROM\n",
    "            read_csv_auto('{input_file}')\n",
    "        WHERE\n",
    "            Freq IS NOT NULL\n",
    "            AND Code IS NOT NULL\n",
    "            AND Date IS NOT NULL\n",
    "            AND Time IS NOT NULL\n",
    "            AND Site IS NOT NULL\n",
    "            AND Power IS NOT NULL\n",
    "            AND Type IS NOT NULL \n",
    "            AND Type = 'LOTEK'\n",
    "            AND Freq IN {tuple(target_frequency_list)}\n",
    "            AND Code IN {tuple(target_code_list)}\n",
    "        ) TO '{output_parquet_file}' (FORMAT PARQUET);\n",
    "    \"\"\"\n",
    "    \n",
    "    # execute query\n",
    "    try:\n",
    "        duckdb.query(sql)\n",
    "    except (duckdb.BinderException, duckdb.InvalidInputException) as error:\n",
    "        print(f\"ERROR:  Passing import of {input_file}. Please review.\")\n",
    "        pass\n",
    "    \n",
    "    return output_parquet_file\n",
    "\n",
    "\n",
    "def generate_orion_parquet_files(orion_dir: str,\n",
    "                                 target_frequency_list: List[float],\n",
    "                                 target_code_list: List[int],\n",
    "                                 output_directory: str) -> List[str]:\n",
    "    \"\"\"Generate ORION parquet files for query.\"\"\"\n",
    "    \n",
    "    # generate the full file list to process\n",
    "    file_list = tqdm(generate_orion_import_file_list(orion_dir))\n",
    "\n",
    "    # process files\n",
    "    processed_files = []\n",
    "    for i in file_list:\n",
    "\n",
    "        # convert all whitespace in Orion text files to commas\n",
    "        raw_csv_file = whitespace_to_csv(i, orion_dir)\n",
    "\n",
    "        # convert CSV file to parquet format\n",
    "        parquet_file = orion_raw_to_parquet(input_file=raw_csv_file,\n",
    "                                            output_directory=output_directory,\n",
    "                                            target_frequency_list=target_frequency_list,\n",
    "                                            target_code_list=target_code_list)\n",
    "        # add processed file to output list\n",
    "        processed_files.append(parquet_file)\n",
    "    \n",
    "    return processed_files\n",
    "\n",
    "\n",
    "def mitas_raw_to_parquet(input_file: str,\n",
    "                         output_directory: str,\n",
    "                         target_frequency_list: List[float],\n",
    "                         target_code_list: List[int],\n",
    "                         daylight_savings_time_spring: str):\n",
    "    \"\"\"Ingest and format an input MITAS file.\"\"\"\n",
    "        \n",
    "    # extract file name from input file\n",
    "    file_name = f\"1_MITAS_{os.path.splitext(os.path.basename(input_file))[0]}\"\n",
    "    \n",
    "    # create output file name\n",
    "    output_parquet_file = os.path.join(output_directory, f\"{file_name}.parquet\")\n",
    "\n",
    "    sql = f\"\"\"\n",
    "    COPY(\n",
    "        SELECT\n",
    "            concat(\n",
    "                CASE\n",
    "                    WHEN length(frequency::VARCHAR) = 4\n",
    "                    THEN frequency::VARCHAR || '000'\n",
    "                    WHEN length(frequency::VARCHAR) = 5\n",
    "                    THEN frequency::VARCHAR || '00'        \n",
    "                    WHEN length(frequency::VARCHAR) = 6\n",
    "                    THEN frequency::VARCHAR || '0' \n",
    "                    ELSE frequency::VARCHAR \n",
    "                END\n",
    "                ,'.'\n",
    "                ,CASE\n",
    "                    WHEN length(codeNumber::VARCHAR) = 1\n",
    "                    THEN '00' || codeNumber::VARCHAR\n",
    "                    WHEN length(codeNumber::VARCHAR) = 2\n",
    "                    THEN '0' || codeNumber::VARCHAR  \n",
    "                    ELSE codeNumber::VARCHAR\n",
    "                END\n",
    "            ) AS fish_id\n",
    "            ,CASE\n",
    "                -- daylight savings time spring adjustment\n",
    "                WHEN \"decodeTimeUTC-04:00\" - INTERVAL 3 HOUR <= '{daylight_savings_time_spring}'\n",
    "                THEN \"decodeTimeUTC-04:00\" - INTERVAL 4 HOUR\n",
    "                ELSE \"decodeTimeUTC-04:00\" - INTERVAL 3 HOUR\n",
    "            END AS date_time\n",
    "            ,ReceiverId AS receiver_id\n",
    "            ,power::INT AS signal_power\n",
    "            ,'{file_name}' AS file_nm\n",
    "        FROM\n",
    "            '{input_file}'\n",
    "        WHERE\n",
    "            frequency IS NOT NULL\n",
    "            AND codeNumber IS NOT NULL\n",
    "            AND \"decodeTimeUTC-04:00\" IS NOT NULL\n",
    "            AND ReceiverId IS NOT NULL\n",
    "            AND power IS NOT NULL\n",
    "            AND frequency IN {tuple(target_frequency_list)}\n",
    "            AND codeNumber IN {tuple(target_code_list)}\n",
    "        ) TO '{output_parquet_file}' (FORMAT PARQUET);\n",
    "    \"\"\"\n",
    "    \n",
    "    # fire query\n",
    "    duckdb.query(sql)\n",
    "    \n",
    "    return output_parquet_file\n",
    "\n",
    "\n",
    "def generate_mitas_parquet_files(mitas_dir: str,\n",
    "                                 target_frequency_list: List[float],\n",
    "                                 target_code_list: List[int],\n",
    "                                 output_directory: str,\n",
    "                                 daylight_savings_time_spring: str) -> List[str]:\n",
    "    \"\"\"Generate MITAS parquet files for use in query.\"\"\"\n",
    "    \n",
    "    # get a list of mitas CSV files\n",
    "    mitas_csv_files = glob.glob(os.path.join(mitas_dir, \"*.csv\"))\n",
    "\n",
    "    processed_files = []\n",
    "    for i in tqdm(mitas_csv_files):\n",
    "\n",
    "        # convert each file to a parquet file\n",
    "        output_file = mitas_raw_to_parquet(input_file=i, \n",
    "                                           output_directory=output_directory,\n",
    "                                           target_frequency_list=target_frequency_list,\n",
    "                                           target_code_list=target_code_list,\n",
    "                                           daylight_savings_time_spring=daylight_savings_time_spring)\n",
    "        \n",
    "        # add processed file to output list\n",
    "        processed_files.append(output_file)\n",
    "        \n",
    "    return processed_files\n",
    "\n",
    "\n",
    "def filter_tagged_fish(df, tagging_df):\n",
    "    \"\"\"Only keep fish in tagging file.\"\"\"\n",
    "    \n",
    "    n_records = df.shape[0]\n",
    "\n",
    "    # only keep fish in tagging file\n",
    "    df = df.loc[df[\"fish_id\"].isin(tagging_df[\"fish_id\"].unique())]\n",
    "\n",
    "    n_dropped = n_records - df.shape[0]\n",
    "\n",
    "    print(f\"Dropped {n_dropped} records for fish not in tagging file.\")\n",
    "    \n",
    "    return df \n",
    "\n",
    "\n",
    "def filter_release_time(df, tagging_df):\n",
    "    \"\"\"Only keep records greater than or equal to release time.\"\"\"\n",
    "    \n",
    "    n_records = df.shape[0]\n",
    "\n",
    "    # get a lookup dictionary of release date times from each fish\n",
    "    fish_release_time_dict = tagging_df.set_index(\"fish_id\")[\"tag_release_date_pst\"].to_dict()\n",
    "\n",
    "    # add field for release time to bound study start\n",
    "    df[\"tag_release_date_pst\"] = df[\"fish_id\"].map(fish_release_time_dict)\n",
    "\n",
    "    # only keep records greater than the fish release time\n",
    "    df = df.loc[df[\"date_time\"] >= df[\"tag_release_date_pst\"]].copy()\n",
    "\n",
    "    df.drop(columns=[\"tag_release_date_pst\"], inplace=True)\n",
    "\n",
    "    n_dropped = n_records - df.shape[0]\n",
    "\n",
    "    print(f\"Dropped {n_dropped} records for detections before release time.\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def filter_study_period(df, \n",
    "                        end_date_time):\n",
    "    \"\"\"Only keep records that span through the study period.\"\"\"\n",
    "    \n",
    "    n_records = df.shape[0]\n",
    "\n",
    "    # only keep records that account for tag life\n",
    "    df = df.loc[df[\"date_time\"] <= end_date_time]\n",
    "\n",
    "    n_dropped = n_records - df.shape[0]\n",
    "\n",
    "    print(f\"Dropped {n_dropped} records exceeding study period date and time.\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def filter_tag_life(df: pd.DataFrame, \n",
    "                    tagging_df: pd.DataFrame, \n",
    "                    max_tag_life_days: float) -> pd.DataFrame:\n",
    "    \"\"\"Only keep records that span through tag life.\"\"\"\n",
    "    \n",
    "    n_records = df.shape[0]\n",
    "    \n",
    "    # create a tag expiration date\n",
    "    tagging_df[\"tag_expire_dt\"] = tagging_df[\"tag_activation_date_pst\"] + pd.Timedelta(days=max_tag_life_days)\n",
    "    \n",
    "    # create a dictionary of tax expiration datetime\n",
    "    tag_expire_dict = tagging_df.set_index(\"fish_id\")[\"tag_expire_dt\"].to_dict()\n",
    "    \n",
    "    # add the expiration date to the input data frame\n",
    "    df[\"tag_expire_dt\"] = df[\"fish_id\"].map(tag_expire_dict)\n",
    "\n",
    "    # only keep records that account for tag life\n",
    "    df = df.loc[df[\"date_time\"] <= df[\"tag_expire_dt\"]]\n",
    "\n",
    "    n_dropped = n_records - df.shape[0]\n",
    "\n",
    "    print(f\"Dropped {n_dropped} records where detection datetime exceeded tag life.\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def filter_drop_duplicate_detections(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Drop duplicate detections by keeping the first files which are Orion files.\"\"\"\n",
    "\n",
    "    n_records = df.shape[0]\n",
    "\n",
    "    # drop duplicates by keeping \"first\" which are the orion files\n",
    "    df.drop_duplicates(subset=[\"fish_id\", \"date_time\", \"site_number\", \"signal_power\"], \n",
    "                       keep=\"first\", \n",
    "                       inplace=True)\n",
    "\n",
    "    n_dropped = n_records - df.shape[0]\n",
    "\n",
    "    print(f\"Dropped {n_dropped} duplicate MITAS and ORION records.\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def filter_raw_data(target_fish_id: str,\n",
    "                    glob_path: str,\n",
    "                    reciever_to_detect_site_dict: dict,\n",
    "                    receiver_to_site_number_dict: dict,\n",
    "                    tagging_df: pd.DataFrame,\n",
    "                    project_end_date: str,\n",
    "                    max_tag_life_days: float) -> pd.DataFrame:\n",
    "    \"\"\"Apply filters to raw data and add detection site and site number.\n",
    "    \n",
    "    Filter 1:  only expected fish in the data \n",
    "    Filter 2:  ensures the fish times are bound by release datetime\n",
    "    Filter 3:  ensures that only detections that fall into the tag life window are considered\n",
    "    Filter 4:  ensure that only detections that fall into the tag life window are considered\n",
    "    Filter 5:  drop duplicates occurring in MITAS and ORION; keep ORION by default\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    sql = f\"\"\"\n",
    "    SELECT\n",
    "        *\n",
    "    FROM \n",
    "        '{glob_path}'\n",
    "    WHERE\n",
    "        fish_id = '{target_fish_id}';\n",
    "    \"\"\"\n",
    "    \n",
    "    df = duckdb.query(sql).df()\n",
    "    \n",
    "    if df.shape[0] == 0:\n",
    "        print(f\"WARNING:  There were no valid detections for fish_id:  '{target_fish_id}'\")\n",
    "        print(f\"WARNING:  Output file will not be created.\")\n",
    "        \n",
    "    else:\n",
    "    \n",
    "        # add detect site\n",
    "        df[\"detect_site\"] = df[\"receiver_id\"].map(reciever_to_detect_site_dict)\n",
    "\n",
    "        # change receiver id to site number\n",
    "        df[\"site_number\"] = df[\"receiver_id\"].map(receiver_to_site_number_dict)\n",
    "\n",
    "        # ensure that only expected fish are in the data\n",
    "        df = filter_tagged_fish(df, tagging_df)\n",
    "\n",
    "        # ensure that fish times are bound by release time\n",
    "        df = filter_release_time(df, tagging_df)\n",
    "\n",
    "        # ensure that only detections that fall into the study period window\n",
    "        df = filter_study_period(df,\n",
    "                                 end_date_time=project_end_date)\n",
    "        \n",
    "        # ensure that only detections that fall into the tag life window are considered\n",
    "        df = filter_tag_life(df,\n",
    "                             tagging_df,\n",
    "                             max_tag_life_days=max_tag_life_days)\n",
    "\n",
    "\n",
    "        # drop duplicates by keeping \"first\" which are the orion files\n",
    "        df = filter_drop_duplicate_detections(df)\n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "def generate_lag_lead_records(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Create lag and lead records for the target fish to show what happened before\n",
    "    and after the target.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # sort data frame\n",
    "    df.sort_values(by=[\"fish_id\", \"detect_site\", \"date_time\"], inplace=True)\n",
    "\n",
    "    # reindex dataset\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    # lag\n",
    "    lag_df = df.shift(periods=1)[[\"fish_id\", \"detect_site\", \"date_time\"]]\n",
    "\n",
    "    # lead\n",
    "    lead_df = df.shift(periods=-1)[[\"fish_id\", \"detect_site\", \"date_time\"]]\n",
    "\n",
    "    # add to main data frame\n",
    "    df[\"lag_fish_id\"] = lag_df[\"fish_id\"]\n",
    "    df[\"lag_detect_site\"] = lag_df[\"detect_site\"]\n",
    "    df[\"lag_date_time\"] = lag_df[\"date_time\"]\n",
    "    df[\"lead_fish_id\"] = lead_df[\"fish_id\"]\n",
    "    df[\"lead_detect_site\"] = lead_df[\"detect_site\"]\n",
    "    df[\"lead_date_time\"] = lead_df[\"date_time\"]\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def create_events(df, hits, seconds, detection_sites):\n",
    "    \n",
    "    df = df.loc[df[\"detect_site\"].isin(detection_sites)].copy()\n",
    "\n",
    "    # create timedelta field in seconds; set\n",
    "    df['time_from_previous_hit'] = np.where(\n",
    "                                    (df.fish_id == df.lag_fish_id) & (df.detect_site == df.lag_detect_site),\n",
    "                                    (df.date_time - df.lag_date_time).fillna(pd.Timedelta('0 days')).values.view('<i8')/10**9,\n",
    "                                    -1)\n",
    "\n",
    "    # create block_id for each event where hits are no more than time threshold seconds apart\n",
    "    df['block_id'] = ((df.time_from_previous_hit >= seconds) | (df.time_from_previous_hit < 0)).astype(int).cumsum()\n",
    "\n",
    "    # get hit count of each block\n",
    "    df['block_count'] = df.groupby(['block_id'])['block_id'].transform('count')\n",
    "\n",
    "    # remove unneeded columns\n",
    "    drop_cols = ['time_from_previous_hit', 'lead_fish_id', 'lag_fish_id', 'lead_detect_site', 'lag_detect_site',\n",
    "                 'lead_date_time', 'lag_date_time']\n",
    "\n",
    "    df.drop(drop_cols, axis=1, inplace=True)\n",
    "\n",
    "    # only keep event blocks that meet the hits per block threshold\n",
    "    df = df[df['block_count'] >= hits]\n",
    "    \n",
    "    # add in hits per sec claus\n",
    "    df[\"grouping\"] = f\"{hits}_{seconds}\"\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def build_first_last_detection(df, detect_site_to_abbrev_dict):\n",
    "    \"\"\"Generate first and last detections at each detect site.\"\"\"\n",
    "\n",
    "    # generate last event time for each detection site\n",
    "    events_last = df.groupby([\"fish_id\", \"grouping\", \"detect_site\"])[\"date_time\"].max().reset_index()\n",
    "    events_last[\"site_abbrev\"] = events_last[\"detect_site\"].map(detect_site_to_abbrev_dict).str.lower() + \"_l\"\n",
    "\n",
    "    # generate first event time for each detection site\n",
    "    events_first = df.groupby([\"fish_id\", \"grouping\", \"detect_site\"])[\"date_time\"].min().reset_index()\n",
    "    events_first[\"site_abbrev\"] = events_first[\"detect_site\"].map(detect_site_to_abbrev_dict).str.lower() + \"_f\"\n",
    "\n",
    "    # combine\n",
    "    events_first_last = pd.concat([events_first, events_last])\n",
    "\n",
    "    return events_first_last.sort_values(by=\"detect_site\")\n",
    "\n",
    "\n",
    "\n",
    "def plot_fish_heatmap(fish_id: str,\n",
    "                      df: pd.DataFrame,\n",
    "                      output_directory: str,\n",
    "                      detect_plot_name_dict: dict,\n",
    "                      site_plot_name_dict: dict,\n",
    "                      time_aggregation: str = \"min\",\n",
    "                      plot_field: str = \"detect_site\",\n",
    "                      plot_type: str = \"power\",\n",
    "                      figsize: tuple = (30, 8),\n",
    "                      title: str = \"\",\n",
    "                      file_name_suffix: str = \"\"):\n",
    "    \n",
    "    if plot_field == \"site_number\":\n",
    "        map_plot_name_dict = site_plot_name_dict\n",
    "\n",
    "        \n",
    "    else:\n",
    "        map_plot_name_dict = detect_plot_name_dict\n",
    "\n",
    "    \n",
    "    beacon_df[f\"{plot_field}_name\"] = beacon_df[plot_field].map(map_plot_name_dict)\n",
    "\n",
    "    df[f\"{plot_field}_name\"] = df[plot_field].map(map_plot_name_dict)\n",
    "\n",
    "    df[\"date\"] = df[\"date_time\"].dt.floor(time_aggregation).dt.strftime('%m-%d %H:%M:00')\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    if plot_type == \"detection\":\n",
    "        \n",
    "        plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
    "\n",
    "        g = sns.heatmap(plot_detections, annot=False, cmap=\"vlag\", ax=ax) #linewidths=0.5, ax=ax)\n",
    "        g.set_title(title)\n",
    "        \n",
    "    elif plot_type == \"power\":\n",
    "        \n",
    "        # more negative power is weaker; closer to 0 is more powerful\n",
    "        plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
    "\n",
    "        g = sns.heatmap(plot_power, annot=False, cmap=\"vlag\", ax=ax) #linewidths=0.5, ax=ax)\n",
    "        g.set_title(title)\n",
    "        \n",
    "    else:\n",
    "        print(f\"Option for 'plot_type' = '{plot_type}' is not available.  Choose either 'detection' or 'power'.\")\n",
    "    \n",
    "    figure = g.get_figure()\n",
    "    figure.savefig(os.path.join(output_directory, f\"{fish_id}_{file_name_suffix}.png\"), dpi=250, bbox_inches=\"tight\")\n",
    "    \n",
    "    plt.close()\n",
    "    \n",
    "\n",
    "\n",
    "def generate(fish_id: str, \n",
    "             parquet_raw_dir: str,\n",
    "             travel_time_template_dtypes: dict,\n",
    "             reciever_to_detect_site_dict: dict,\n",
    "             receiver_to_site_number_dict: dict,\n",
    "             signal_power_threshold_dict: dict,\n",
    "             detect_site_to_abbrev_dict: dict,\n",
    "             detection_site_abbrev_list: list,\n",
    "             detect_plot_name_dict: dict,\n",
    "             site_plot_name_dict: dict,\n",
    "             tagging_df: pd.DataFrame,\n",
    "             beacon_df: pd.DataFrame,\n",
    "             project_end_date: str,\n",
    "             max_tag_life_days: int,\n",
    "             use_events: bool, \n",
    "             consider_dam_operations: bool,\n",
    "             output_plot_directory: str,\n",
    "             simulation: str,\n",
    "             generate_plots: bool = True):\n",
    "    \n",
    "    \n",
    "    # get path to glob all raw parquet files\n",
    "    glob_path = os.path.join(parquet_raw_dir, \"*.parquet\")\n",
    "\n",
    "\n",
    "    # process    \n",
    "    df = filter_raw_data(fish_id,\n",
    "                         glob_path,\n",
    "                         reciever_to_detect_site_dict=reciever_to_detect_site_dict,\n",
    "                         receiver_to_site_number_dict=receiver_to_site_number_dict,\n",
    "                         tagging_df=tagging_df,\n",
    "                         project_end_date=project_end_date,\n",
    "                         max_tag_life_days=max_tag_life_days)\n",
    "    \n",
    "#     df.sort_values(by=[\"detect_site\", \"date_time\"]).to_csv(f\"/Users/d3y010/projects/telemetry/mm_sum_2022/data/outputs/{simulation}/clean/clean_by_fish_id/{fish_id}.csv\", index=False)\n",
    "    \n",
    "#     # set level of time aggregation for plots\n",
    "#     if df.shape[0] <= 50000:\n",
    "#         time_aggregation = \"min\"\n",
    "#         time_designation = \"minute\"\n",
    "#     else:\n",
    "#         time_aggregation = \"H\"\n",
    "#         time_designation = \"hour\"\n",
    "        \n",
    "#     print(\"Producing clean plots...\")\n",
    "\n",
    "#     # plot heatmap of detections  \n",
    "#     plot_fish_heatmap(fish_id=fish_id,\n",
    "#                       df=df,\n",
    "#                       output_directory=f\"/Users/d3y010/projects/telemetry/mm_sum_2022/data/outputs/{simulation}/clean/clean_plots\",\n",
    "#                       detect_plot_name_dict=detect_plot_name_dict,\n",
    "#                       site_plot_name_dict=site_plot_name_dict,\n",
    "#                       time_aggregation=time_aggregation,\n",
    "#                       plot_field=\"site_number\",\n",
    "#                       plot_type=\"detection\",\n",
    "#                       figsize=(60, 7),\n",
    "#                       title=f\"Clean detections by site number aggregated to {time_designation}:  {fish_id}\",\n",
    "#                       file_name_suffix=\"event_detections-by-site_number\")\n",
    "\n",
    "#     # plot heatmap of signal power\n",
    "#     plot_fish_heatmap(fish_id=fish_id,\n",
    "#                       df=df,\n",
    "#                       output_directory=f\"/Users/d3y010/projects/telemetry/mm_sum_2022/data/outputs/{simulation}/clean/clean_plots\",\n",
    "#                       detect_plot_name_dict=detect_plot_name_dict,\n",
    "#                       site_plot_name_dict=site_plot_name_dict,\n",
    "#                       time_aggregation=time_aggregation,\n",
    "#                       plot_field=\"site_number\",\n",
    "#                       plot_type=\"power\",\n",
    "#                       figsize=(60, 7),\n",
    "#                       title=f\"Clean signal power per detecion by site number aggregated to {time_designation}:  {fish_id}\",\n",
    "#                       file_name_suffix=\"event_signal_power-by-site_number\")\n",
    "\n",
    "\n",
    "#     # plot heatmap of detections  \n",
    "#     plot_fish_heatmap(fish_id=fish_id,\n",
    "#                       df=df,\n",
    "#                       output_directory=f\"/Users/d3y010/projects/telemetry/mm_sum_2022/data/outputs/{simulation}/clean/clean_plots\",\n",
    "#                       detect_plot_name_dict=detect_plot_name_dict,\n",
    "#                       site_plot_name_dict=site_plot_name_dict,\n",
    "#                       time_aggregation=time_aggregation,\n",
    "#                       plot_field=\"detect_site\",\n",
    "#                       plot_type=\"detection\",\n",
    "#                       figsize=(60, 7),\n",
    "#                       title=f\"Clean detections by detecion site aggregated to {time_designation}:  {fish_id}\",\n",
    "#                       file_name_suffix=\"event_detections-by-detect_site\")\n",
    "\n",
    "#     # plot heatmap of signal power\n",
    "#     plot_fish_heatmap(fish_id=fish_id,\n",
    "#                       df=df,\n",
    "#                       output_directory=f\"/Users/d3y010/projects/telemetry/mm_sum_2022/data/outputs/{simulation}/clean/clean_plots\",\n",
    "#                       detect_plot_name_dict=detect_plot_name_dict,\n",
    "#                       site_plot_name_dict=site_plot_name_dict,\n",
    "#                       time_aggregation=time_aggregation,\n",
    "#                       plot_field=\"detect_site\",\n",
    "#                       plot_type=\"power\",\n",
    "#                       figsize=(60, 7),\n",
    "#                       title=f\"Clean signal power per detection by detect site aggregated to {time_designation}:  {fish_id}\",\n",
    "#                       file_name_suffix=\"event_signal_power-by-detect_site\")\n",
    "\n",
    "    if use_events:\n",
    "\n",
    "        # create lag and lead records\n",
    "        df = generate_lag_lead_records(df)\n",
    "\n",
    "        # get a list of detection sites per hits per second condition\n",
    "        cond_one = beacon_df.loc[beacon_df[\"hits_seconds_run\"] == \"3_60\"][\"detect_site\"].to_list()\n",
    "        cond_two = beacon_df.loc[beacon_df[\"hits_seconds_run\"] == \"2_120\"][\"detect_site\"].to_list()\n",
    "\n",
    "        # create events per condition\n",
    "        dfa = create_events(df, hits=3, seconds=60, detection_sites=cond_one)\n",
    "        dfb = create_events(df, hits=2, seconds=120, detection_sites=cond_two)\n",
    "\n",
    "        # merge output\n",
    "        events_nops = pd.concat([dfa, dfb])\n",
    "\n",
    "    else:\n",
    "\n",
    "        # if not calculating events\n",
    "        events_nops = df.copy()\n",
    "\n",
    "        events_nops[\"grouping\"] = None\n",
    "\n",
    "    # only keep event detections that are greater than or equal to the site specific thresholds for signal power\n",
    "    events_nops = events_nops.loc[events_nops[\"signal_power\"] >= events_nops[\"site_number\"].map(signal_power_threshold_dict)]\n",
    "\n",
    "    # generate first and last detections per detection site\n",
    "    events_nops_tt = build_first_last_detection(events_nops, detect_site_to_abbrev_dict)\n",
    "    \n",
    "    if consider_dam_operations:\n",
    "    \n",
    "        # only process on dam detections since this is the only thing that dam operations will influence\n",
    "        events_ops = events_nops.loc[events_nops[\"detect_site\"] == dam_detect_site].copy()\n",
    "\n",
    "        # round datetime to base hour\n",
    "        events_ops['date_time_pst'] = pd.to_datetime(events_ops[\"date_time\"], errors='coerce').values.astype('datetime64[h]')\n",
    "\n",
    "        # join events and dam ops data frames on rounded datetime\n",
    "        events_ops = pd.merge(events_ops, dam_ops_df, how='left', on='date_time_pst')\n",
    "\n",
    "        # if site is closed in dam ops, 0; else 1 for open\n",
    "        # TODO:  find better way to handle site specific conditional calls that correspond with the beacon file\n",
    "        events_ops['active'] = np.where(((events_ops.site_number == 4) & (events_ops[\"4\"].astype(int) == 0))\n",
    "                                | ((events_ops.site_number == 5) & (events_ops[\"5\"].astype(int) == 0))\n",
    "                                | ((events_ops.site_number == 6) & (events_ops[\"6\"].astype(int) == 0))\n",
    "                                | ((events_ops.site_number == 7) & (events_ops[\"7\"].astype(int) == 0))\n",
    "                                | ((events_ops.site_number == 9) & (events_ops[\"9\"].astype(int) == 0))\n",
    "                                | ((events_ops.site_number == 10) & (events_ops[\"10\"].astype(int) == 0)),\n",
    "                                0,\n",
    "                                1)\n",
    "\n",
    "        # only keep events where site was open\n",
    "        events_ops = events_ops.loc[events_ops.active == 1]\n",
    "\n",
    "        # drop unneeded columns\n",
    "        # TODO: remove the site_* and dam sites based on what is in the beacon file rather than this static list\n",
    "        events_ops = events_ops.drop(['date_time_pst', '4', '5', '6', '7',\n",
    "                                      '9', '10', 'active', 'sp_dis', 'tur_dis', 'weir_dis',\n",
    "                                      'total_dis', 'fby_z', 'treatment', 'pool_stage'], \n",
    "                                     axis=1)\n",
    "\n",
    "        # update events without operations considered to remove dam events that were not possible due to dam closure\n",
    "        events_ops = pd.concat([events_nops.loc[events_nops[\"detect_site\"] != dam_detect_site], events_ops])\n",
    "\n",
    "        # generate first and last detections per detection site\n",
    "        events_ops_tt = build_first_last_detection(events_ops, detect_site_to_abbrev_dict)\n",
    "        \n",
    "    else:\n",
    "        events_ops = events_nops\n",
    "        events_ops_tt = events_nops_tt\n",
    "\n",
    "    # sns.set(rc={'axes.facecolor':'whitesmoke'})\n",
    "    \n",
    "    \n",
    "    if events_ops.shape[0] == 0:\n",
    "        print(f\"No events available.\")\n",
    "        generate_plots = False\n",
    "        \n",
    "    if generate_plots:\n",
    "        \n",
    "        print(\"Producing events plots...\")\n",
    "        \n",
    "        # set level of time aggregation for plots\n",
    "        if events_ops.shape[0] <= 50000:\n",
    "            time_aggregation = \"min\"\n",
    "            time_designation = \"minute\"\n",
    "        else:\n",
    "            time_aggregation = \"H\"\n",
    "            time_designation = \"hour\"\n",
    "\n",
    "        # plot heatmap of detections  \n",
    "        plot_fish_heatmap(fish_id=fish_id,\n",
    "                          df=events_ops,\n",
    "                          output_directory=output_plot_directory,\n",
    "                          detect_plot_name_dict=detect_plot_name_dict,\n",
    "                          site_plot_name_dict=site_plot_name_dict,\n",
    "                          time_aggregation=time_aggregation,\n",
    "                          plot_field=\"site_number\",\n",
    "                          plot_type=\"detection\",\n",
    "                          figsize=(60, 7),\n",
    "                          title=f\"Event detections by site number aggregated to {time_designation}:  {fish_id}\",\n",
    "                          file_name_suffix=\"event_detections-by-site_number\")\n",
    "\n",
    "        # plot heatmap of signal power\n",
    "        plot_fish_heatmap(fish_id=fish_id,\n",
    "                          df=events_ops,\n",
    "                          output_directory=output_plot_directory,\n",
    "                          detect_plot_name_dict=detect_plot_name_dict,\n",
    "                          site_plot_name_dict=site_plot_name_dict,\n",
    "                          time_aggregation=time_aggregation,\n",
    "                          plot_field=\"site_number\",\n",
    "                          plot_type=\"power\",\n",
    "                          figsize=(60, 7),\n",
    "                          title=f\"Event signal power per detecion by site number aggregated to {time_designation}:  {fish_id}\",\n",
    "                          file_name_suffix=\"event_signal_power-by-site_number\")\n",
    "\n",
    "\n",
    "        # plot heatmap of detections  \n",
    "        plot_fish_heatmap(fish_id=fish_id,\n",
    "                          df=events_ops,\n",
    "                          output_directory=output_plot_directory,\n",
    "                          detect_plot_name_dict=detect_plot_name_dict,\n",
    "                          site_plot_name_dict=site_plot_name_dict,\n",
    "                          time_aggregation=time_aggregation,\n",
    "                          plot_field=\"detect_site\",\n",
    "                          plot_type=\"detection\",\n",
    "                          figsize=(60, 7),\n",
    "                          title=f\"Event detections by detecion site aggregated to {time_designation}:  {fish_id}\",\n",
    "                          file_name_suffix=\"event_detections-by-detect_site\")\n",
    "\n",
    "        # plot heatmap of signal power\n",
    "        plot_fish_heatmap(fish_id=fish_id,\n",
    "                          df=events_ops,\n",
    "                          output_directory=output_plot_directory,\n",
    "                          detect_plot_name_dict=detect_plot_name_dict,\n",
    "                          site_plot_name_dict=site_plot_name_dict,\n",
    "                          time_aggregation=time_aggregation,\n",
    "                          plot_field=\"detect_site\",\n",
    "                          plot_type=\"power\",\n",
    "                          figsize=(60, 7),\n",
    "                          title=f\"Event signal power per detection by detect site aggregated to {time_designation}:  {fish_id}\",\n",
    "                          file_name_suffix=\"event_signal_power-by-detect_site\")\n",
    "\n",
    "    # build a dictionary of field with empty data\n",
    "    travel_time_template_dict = {i: [] for i in travel_time_template_dtypes.keys()}\n",
    "\n",
    "    # generate travel time template\n",
    "    travel_time_template = pd.DataFrame(travel_time_template_dict).astype(travel_time_template_dtypes)\n",
    "\n",
    "    # add fish ids to the travel time file\n",
    "    travel_time_template[\"fish_id\"] = tagging_df.index\n",
    "\n",
    "    # set template site designation to 0 \n",
    "    travel_time_template[detection_site_abbrev_list] = 0\n",
    "\n",
    "    # generate a list of detection site first and last columns in order\n",
    "    detection_site_time_columns = []\n",
    "    for i in detection_site_abbrev_list:\n",
    "        detection_site_time_columns.append(f\"{i}_f\")\n",
    "        detection_site_time_columns.append(f\"{i}_l\")\n",
    "\n",
    "    # sort by fish id\n",
    "    travel_time_template.sort_values(by=[\"fish_id\"], inplace=True)\n",
    "\n",
    "    # set index to fish id\n",
    "    travel_time_template.set_index(\"fish_id\", inplace=True)\n",
    "    \n",
    "\n",
    "    if events_ops.shape[0] > 0:\n",
    "        events_ops_tt_layout = pd.pivot_table(events_ops_tt,\n",
    "                                               values=\"date_time\",\n",
    "                                               index=[\"fish_id\"],\n",
    "                                               columns=[\"site_abbrev\"]).rename_axis(None, axis=1).reset_index()\n",
    "    else:\n",
    "        events_ops_tt_layout = pd.DataFrame({\"fish_id\": [fish_id], \"date_time\": [pd.NaT]})\n",
    "    \n",
    "    events_ops_tt_layout[\"pit_code\"] = events_ops_tt_layout[\"fish_id\"].map(pit_tag_dict)\n",
    "    events_ops_tt_layout[\"srr\"] = events_ops_tt_layout[\"fish_id\"].map(srr_dict)\n",
    "    events_ops_tt_layout[\"rel_name\"] = events_ops_tt_layout[\"fish_id\"].map(release_name_dict)\n",
    "    events_ops_tt_layout[\"lot\"] = events_ops_tt_layout[\"fish_id\"].map(lot_dict)\n",
    "    events_ops_tt_layout[\"act_datetime\"] = events_ops_tt_layout[\"fish_id\"].map(activation_dict)\n",
    "    events_ops_tt_layout[\"release_datetime\"] = events_ops_tt_layout[\"fish_id\"].map(release_dict)\n",
    "    events_ops_tt_layout[\"mort_xlat\"] = events_ops_tt_layout[\"fish_id\"].map(mort_dict)\n",
    "\n",
    "    events_ops_tt_layout[\"hole\"] = \"NA\"\n",
    "    events_ops_tt_layout[\"subhole\"] = \"NA\"\n",
    "    events_ops_tt_layout[\"rel_weir_time_s\"] = 0\n",
    "    events_ops_tt_layout[\"pool_stage\"] = \"\"\n",
    "    events_ops_tt_layout[\"release_stage\"] = \"NA\"\n",
    "    events_ops_tt_layout[\"censor\"] = \"\"\n",
    "    events_ops_tt_layout[\"altered\"] = \"\"\n",
    "    events_ops_tt_layout[\"comments\"] = \"\"\n",
    "    \n",
    "    for i in detection_site_abbrev_list:\n",
    "        events_ops_tt_layout[i] = 0\n",
    "        \n",
    "        first = f\"{i}_f\"\n",
    "        last = f\"{i}_l\"\n",
    "        \n",
    "        if first not in events_ops_tt_layout:\n",
    "            events_ops_tt_layout[first] = pd.NaT\n",
    "        \n",
    "        if last not in events_ops_tt_layout:\n",
    "            events_ops_tt_layout[last] = pd.NaT\n",
    "\n",
    "    events_ops_tt_layout = events_ops_tt_layout[list(travel_time_template.reset_index().columns)].set_index(\"fish_id\")\n",
    "\n",
    "    # update template fields for each detection site where an event was logged regardless of whether or not the fish passed the site\n",
    "    x = events_ops.set_index(\"fish_id\")[\"detect_site\"].map({i: detect_site_to_abbrev_dict[i].lower() for i in detect_site_to_abbrev_dict.keys()}).reset_index()\n",
    "\n",
    "    x[\"detected\"] = 1\n",
    "\n",
    "    detect_designation = pd.pivot_table(x, \n",
    "                                        values=\"detected\", \n",
    "                                        index=\"fish_id\", \n",
    "                                        columns=\"detect_site\", \n",
    "                                        fill_value=0).rename_axis(None, axis=1)\n",
    "\n",
    "    # update the template data frame with the new data\n",
    "    events_ops_tt_layout.update(detect_designation)\n",
    "\n",
    "    travel_time_df = events_ops_tt_layout.copy()\n",
    "\n",
    "    # # create a dictionary of detection site abbreviations to the the detect site numbers\n",
    "    # abbrev_to_detect_sites_dict = {detect_site_to_abbrev_dict[x]: x for x in detect_site_to_abbrev_dict.keys()}\n",
    "\n",
    "#     if events_ops.shape[0] > 0:\n",
    "#         travel_time_df = force_last_detection_by_travel_order(fish_id=fish_id,\n",
    "#                                                               travel_time_df=travel_time_df,\n",
    "#                                                               events_df=events_ops,\n",
    "#                                                               abbrev_to_detect_sites_dict=abbrev_to_detect_sites_dict,\n",
    "#                                                               detection_site_abbrev_list=detection_site_abbrev_list)\n",
    "\n",
    "#     # create route of passage (hole, subhole)\n",
    "#     travel_time_df = determine_route_of_passage(travel_time_df=travel_time_df, \n",
    "#                                                 events_df=events_ops,\n",
    "#                                                 dam_detect_site=dam_detect_site,\n",
    "#                                                 hole_dict=hole_dict,\n",
    "#                                                 subhole_dict=subhole_dict)\n",
    "\n",
    "\n",
    "    # # add release stage designations\n",
    "    # for stage in release_stage_dict.keys():\n",
    "# \n",
    "#         travel_time_df[\"release_stage\"] = np.where((travel_time_df[\"release_datetime\"] >= release_stage_dict[stage][\"start\"]) & \n",
    "#                                                    (travel_time_df[\"release_datetime\"] <= release_stage_dict[stage][\"end\"]),\n",
    "#                                                    stage,\n",
    "#                                                    travel_time_df[\"release_stage\"])\n",
    "        \n",
    "#         travel_time_df[\"pool_stage\"] = np.where((travel_time_df[\"dam_l\"] >= release_stage_dict[stage][\"start\"]) & \n",
    "#                                            (travel_time_df[\"dam_l\"] <= release_stage_dict[stage][\"end\"]),\n",
    "#                                            stage,\n",
    "#                                            travel_time_df[\"pool_stage\"])\n",
    "        \n",
    "    # # set fby last to dam lastfor fish with a dam last detection\n",
    "    # travel_time_df[\"fby_l\"] = np.where(~travel_time_df[\"dam_l\"].isnull(),\n",
    "    #                                    travel_time_df[\"dam_l\"],\n",
    "    #                                    travel_time_df[\"fby_l\"])\n",
    "    \n",
    "    # calculate the releative weir time in seconds\n",
    "    travel_time_df[\"rel_weir_time_s\"] = (travel_time_df['tw_l'] - travel_time_df['tw_f']).dt.seconds.fillna(0)\n",
    "\n",
    "    return travel_time_df, events_ops\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b270e99-3e26-47bf-8e4d-8fb3445d9802",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "710bdebc-744b-42ef-90f4-75ea08fd122b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# project directory\n",
    "# root_dir = \"/Users/d3y010/projects/telemetry/mm_sum_2022\"\n",
    "root_dir = \"C:/Users/mcca512/OneDrive - PNNL/McCann Documents/MMD Adult Study/mmd_sum_2022\"\n",
    "\n",
    "# data directory holding raw data\n",
    "data_dir = os.path.join(root_dir, \"data\")\n",
    "\n",
    "# mitas raw data directory\n",
    "mitas_dir = os.path.join(data_dir, \"mitas\")\n",
    "\n",
    "# orion raw data directory\n",
    "orion_dir = os.path.join(data_dir, \"orion\")\n",
    "\n",
    "# output directory\n",
    "output_dir = os.path.join(data_dir, \"outputs\")\n",
    "\n",
    "# directory to hold formatted raw parquet files for query\n",
    "parquet_raw_dir = os.path.join(data_dir, \"parquet_raw_data\")\n",
    "\n",
    "# project start date\n",
    "project_start_date = \"2022-06-02 00:00:00\"\n",
    "\n",
    "# project end date\n",
    "project_end_date = \"2022-11-01 00:00:00\"\n",
    "\n",
    "# daylight savings time spring start\n",
    "daylight_savings_time_spring = \"2022-03-12 02:00:00\"\n",
    "\n",
    "# maximum tag life days\n",
    "max_tag_life_days = 93.4\n",
    "\n",
    "# supporting files\n",
    "beacon_file = os.path.join(root_dir, \"data\", \"load_db\", \"tbl_beacons_mmd_summer_20221011.csv\")\n",
    "tagging_file = os.path.join(root_dir, \"data\", \"load_db\", \"acttagrel_mmd_rt_20221102.xlsx\")\n",
    "# dam_ops_file = os.path.join(root_dir, \"data\", \"load_db\", \"Hourly_dam_ops_foster_2022_final_091522.csv\")\n",
    "\n",
    "# for reproducibility of any stochastic process\n",
    "np.random.seed(123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "395b8667-1dc2-40d2-bdb8-7e92acd38fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for use with plot_field = detect_site\n",
    "detect_plot_name_dict = {1: '01_TW',\n",
    "                         2: '02_ED1',\n",
    "                         3: '03_EU2',\n",
    "                         4: '04_LD1',\n",
    "                         5: '05_LM2',\n",
    "                         6: '06_LU3',\n",
    "                         7: '07_PS'}\n",
    "\n",
    "# for use with plot field = site_number\n",
    "site_plot_name_dict = {1: \"order-01_TWS\",\n",
    "                      2: \"order-02_TWN\",\n",
    "                      3: \"order-03_ED1\",\n",
    "                      5: \"order-05_EU2\",\n",
    "                      6: \"order-06_LD1\",\n",
    "                      7: \"order-07_LM2\",\n",
    "                      8: \"order-08_LU3\",\n",
    "                      9: \"order-09_PSN\",\n",
    "                      10: \"order-10_PSS\"}\n",
    "\n",
    "# list of detection sites in travel order\n",
    "detection_site_abbrev_list = ['tw', 'ed1', 'eu2', 'ld1', 'lm2', 'lu3', 'ps']\n",
    "\n",
    "# dictionary of detection sites to travel time file abbreviation\n",
    "detect_site_to_abbrev_dict = {1: 'tw',\n",
    "                              2: 'ed1',\n",
    "                              3: 'eu2',\n",
    "                              4: 'ld1',\n",
    "                              5: 'lm2',\n",
    "                              6: 'lu3',\n",
    "                              7: 'ps'}\n",
    "\n",
    "# dictionary of data types for the travel time data frame\n",
    "travel_time_template_dtypes = {\n",
    "    \"fish_id\": str,\n",
    "    \"pit_code\": str,\n",
    "    \"rel_name\": str,\n",
    "    \"lot\": int,\n",
    "    \"srr\": str,\n",
    "    \"act_datetime\": \"datetime64[ns]\",\n",
    "    \"release_datetime\": \"datetime64[ns]\",\n",
    "    \"hole\": str,\n",
    "    \"subhole\": str,\n",
    "    \"tw\": int,\n",
    "    \"ed1\": int,\n",
    "    \"eu2\": int,\n",
    "    \"ld1\": int,\n",
    "    \"lm2\": int,\n",
    "    \"lu3\": int,\n",
    "    \"ps\": int,\n",
    "    \"tw_f\": \"datetime64[ns]\",\n",
    "    \"tw_l\": \"datetime64[ns]\",\n",
    "    \"ed1_f\": \"datetime64[ns]\",\n",
    "    \"ed1_l\": \"datetime64[ns]\",\n",
    "    \"eu2_f\": \"datetime64[ns]\",\n",
    "    \"eu2_l\": \"datetime64[ns]\",\n",
    "    \"ld1_f\": \"datetime64[ns]\",\n",
    "    \"ld1_l\": \"datetime64[ns]\",\n",
    "    \"lm2_f\": \"datetime64[ns]\",\n",
    "    \"lm2_l\": \"datetime64[ns]\",\n",
    "    \"lu3_f\": \"datetime64[ns]\",\n",
    "    \"lu3_l\": \"datetime64[ns]\",\n",
    "    \"ps_f\": \"datetime64[ns]\",\n",
    "    \"ps_l\": \"datetime64[ns]\",\n",
    "    \"rel_weir_time_s\": int,\n",
    "    \"pool_stage\": str,\n",
    "    \"censor\": int,\n",
    "    \"altered\": int,\n",
    "    \"mort_xlat\": int,\n",
    "    \"release_stage\": str,\n",
    "    \"comments\": str\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0f890d-232a-4564-90f7-15dbe62d51fc",
   "metadata": {},
   "source": [
    "## Read in beacon and tagging files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34a3220d-7d14-4d25-a874-7d5fe8c7580c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in beacon file\n",
    "beacon_df = pd.read_csv(beacon_file)\n",
    "\n",
    "# # build a dictionary of receiver id to detect site\n",
    "reciever_to_detect_site_dict = beacon_df.set_index(\"receiver_id\")[\"detect_site\"].to_dict()\n",
    "\n",
    "# construct a dictionary of receiver id to site number\n",
    "receiver_to_site_number_dict = beacon_df.set_index(\"receiver_id\")[\"site_number\"].to_dict()\n",
    "\n",
    "# read in tagging data\n",
    "tagging_df = read_tagging_file(tagging_file)\n",
    "\n",
    "# create a list of valid fish ids to process\n",
    "fish_array = tagging_df[\"fish_id\"].unique()\n",
    "\n",
    "# get a dict of PIT tags per fish_id\n",
    "pit_tag_dict = tagging_df.set_index(\"fish_id\")[\"pit_code\"].to_dict()\n",
    "\n",
    "# get a dict of SRR per fish_id\n",
    "srr_dict = tagging_df.set_index(\"fish_id\")[\"srr\"].to_dict()\n",
    "release_name_dict = tagging_df.set_index(\"fish_id\")[\"release_location_xlat\"].to_dict()\n",
    "\n",
    "# there is no lot in the tagging file; using srr as a proxy\n",
    "lot_dict = tagging_df.set_index(\"fish_id\")[\"srr\"].to_dict()\n",
    "\n",
    "activation_dict = tagging_df.set_index(\"fish_id\")[\"tag_activation_date_pst\"].to_dict()\n",
    "release_dict = tagging_df.set_index(\"fish_id\")[\"tag_release_date_pst\"].to_dict()\n",
    "mort_dict = tagging_df.set_index(\"fish_id\")[\"mort_xlat\"].to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b09ba47f-5e58-429d-814e-6bfc1a8299ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate lists of expected frequencies and codes from tagging file\n",
    "fish_id_array = tagging_df[\"fish_id\"].values\n",
    "target_frequency_list = np.unique([float(i[:7]) for i in fish_id_array])\n",
    "target_code_list = np.unique([int(i[-3:]) for i in fish_id_array])\n",
    "\n",
    "# generate a list of expected site numbers from the beacons file\n",
    "target_site_number_list = beacon_df[\"site_number\"].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb4ff16-913b-4faa-b738-a7d17180c2a7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Convert native input files to parquet files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ad94f6-c4ef-4d3b-b060-799977f79c6e",
   "metadata": {},
   "source": [
    "Once the MITAS and ORION files have been built, they do not need to be built again unless new data is added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4449a4cc-0561-42fe-b546-654fce4f4c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [02:06<00:00,  3.08s/it]\n"
     ]
    }
   ],
   "source": [
    "# generate formatted raw files into parquet format for query\n",
    "mitas_raw_parquet_files = generate_mitas_parquet_files(mitas_dir=mitas_dir,\n",
    "                                                       target_frequency_list=target_frequency_list,\n",
    "                                                       target_code_list=target_code_list, \n",
    "                                                       output_directory=parquet_raw_dir,\n",
    "                                                       daylight_savings_time_spring=daylight_savings_time_spring)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c87d7a11-37a0-40b4-861d-3f1cd8108c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:  Text file 'C:/Users/mcca512/OneDrive - PNNL/McCann Documents/MMD Adult Study/mmd_sum_2022\\data\\orion\\20221011\\Site2_20221011.txt' is smaller than or equal to the hex file size (bytes).\n",
      "Text file size: 2882, Hex file size: 3584, Difference (hex - text): 702\n",
      "Removing files from import.  Please review.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [06:54<00:00,  4.15s/it]\n"
     ]
    }
   ],
   "source": [
    "# generate formatted raw files into parquet format for query\n",
    "orion_raw_parquet_files = generate_orion_parquet_files(orion_dir=orion_dir,\n",
    "                                                       target_frequency_list=target_frequency_list,\n",
    "                                                       target_code_list=target_code_list, \n",
    "                                                       output_directory=parquet_raw_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6b14ba-95e7-4e34-89ac-7b32557d41e9",
   "metadata": {},
   "source": [
    "## Create percentile thresholds per receiver id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b3ad3de5-00a2-4fcf-bc73-ef5e6a30a037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating percentile:  0.8\n",
      "   site_number  signal_power  percentile\n",
      "0            1           -70          80\n",
      "1            2           -75          80\n",
      "2            3           -66          80\n",
      "3            4           -70          80\n",
      "4            5           -90          80\n",
      "5            6           -87          80\n",
      "6            7           -90          80\n",
      "7            8           -96          80\n",
      "8            9           -78          80\n",
      "Processing fish:  166.620.101\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 10918 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 67 records where detection datetime exceeded tag life.\n",
      "Dropped 1166485 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  166.620.102\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 8984 records for detections before release time.\n",
      "Dropped 2 records exceeding study period date and time.\n",
      "Dropped 215 records where detection datetime exceeded tag life.\n",
      "Dropped 552315 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  166.620.103\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 9955 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 53 records where detection datetime exceeded tag life.\n",
      "Dropped 157236 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  166.620.104\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 45563 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 40 records where detection datetime exceeded tag life.\n",
      "Dropped 1285332 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  166.620.105\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 25129 records for detections before release time.\n",
      "Dropped 2 records exceeding study period date and time.\n",
      "Dropped 214 records where detection datetime exceeded tag life.\n",
      "Dropped 147096 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  166.620.106\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 30017 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 816 records where detection datetime exceeded tag life.\n",
      "Dropped 407308 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  166.620.107\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 40413 records for detections before release time.\n",
      "Dropped 105419 records exceeding study period date and time.\n",
      "Dropped 6479802 records where detection datetime exceeded tag life.\n",
      "Dropped 5109295 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  166.620.108\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 31889 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 17 records where detection datetime exceeded tag life.\n",
      "Dropped 1274774 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  166.620.109\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 26265 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 4 records where detection datetime exceeded tag life.\n",
      "Dropped 1324 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  166.620.110\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 21778 records for detections before release time.\n",
      "Dropped 45 records exceeding study period date and time.\n",
      "Dropped 401472 records where detection datetime exceeded tag life.\n",
      "Dropped 1655845 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  166.620.111\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 19929 records for detections before release time.\n",
      "Dropped 10 records exceeding study period date and time.\n",
      "Dropped 1826487 records where detection datetime exceeded tag life.\n",
      "Dropped 4585721 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  166.620.112\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 16232 records for detections before release time.\n",
      "Dropped 34 records exceeding study period date and time.\n",
      "Dropped 2213 records where detection datetime exceeded tag life.\n",
      "Dropped 6126 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  166.740.116\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 10246 records for detections before release time.\n",
      "Dropped 3 records exceeding study period date and time.\n",
      "Dropped 503 records where detection datetime exceeded tag life.\n",
      "Dropped 2491270 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  166.740.117\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 8768 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 68 records where detection datetime exceeded tag life.\n",
      "Dropped 465039 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  166.740.118\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 9868 records for detections before release time.\n",
      "Dropped 13 records exceeding study period date and time.\n",
      "Dropped 76302 records where detection datetime exceeded tag life.\n",
      "Dropped 966866 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  166.740.119\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 43688 records for detections before release time.\n",
      "Dropped 29 records exceeding study period date and time.\n",
      "Dropped 431340 records where detection datetime exceeded tag life.\n",
      "Dropped 1838574 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  166.740.120\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 40469 records for detections before release time.\n",
      "Dropped 2 records exceeding study period date and time.\n",
      "Dropped 67 records where detection datetime exceeded tag life.\n",
      "Dropped 260429 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  166.740.121\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 18696 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 70 records where detection datetime exceeded tag life.\n",
      "Dropped 1101736 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  166.740.122\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 44299 records for detections before release time.\n",
      "Dropped 6 records exceeding study period date and time.\n",
      "Dropped 173 records where detection datetime exceeded tag life.\n",
      "Dropped 1972 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  166.740.123\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 20673 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 63 records where detection datetime exceeded tag life.\n",
      "Dropped 1561 duplicate MITAS and ORION records.\n",
      "No events available.\n",
      "Processing fish:  166.740.124\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 15683 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 16 records where detection datetime exceeded tag life.\n",
      "Dropped 136805 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  166.740.125\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 17214 records for detections before release time.\n",
      "Dropped 2 records exceeding study period date and time.\n",
      "Dropped 133 records where detection datetime exceeded tag life.\n",
      "Dropped 888 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  166.740.126\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 11917 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 9 records where detection datetime exceeded tag life.\n",
      "Dropped 240 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  166.740.127\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 6743 records for detections before release time.\n",
      "Dropped 2 records exceeding study period date and time.\n",
      "Dropped 19 records where detection datetime exceeded tag life.\n",
      "Dropped 269 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  166.765.131\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 13493 records for detections before release time.\n",
      "Dropped 2 records exceeding study period date and time.\n",
      "Dropped 149 records where detection datetime exceeded tag life.\n",
      "Dropped 150531 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  166.765.132\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 11302 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 88 records where detection datetime exceeded tag life.\n",
      "Dropped 453 duplicate MITAS and ORION records.\n",
      "No events available.\n",
      "Processing fish:  166.765.133\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 10739 records for detections before release time.\n",
      "Dropped 22 records exceeding study period date and time.\n",
      "Dropped 1358 records where detection datetime exceeded tag life.\n",
      "Dropped 670898 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  166.765.134\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 69709 records for detections before release time.\n",
      "Dropped 204 records exceeding study period date and time.\n",
      "Dropped 12162 records where detection datetime exceeded tag life.\n",
      "Dropped 2068452 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  166.765.135\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 48330 records for detections before release time.\n",
      "Dropped 2 records exceeding study period date and time.\n",
      "Dropped 335 records where detection datetime exceeded tag life.\n",
      "Dropped 1447 duplicate MITAS and ORION records.\n",
      "No events available.\n",
      "Processing fish:  166.765.136\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 12885 records for detections before release time.\n",
      "Dropped 4 records exceeding study period date and time.\n",
      "Dropped 92 records where detection datetime exceeded tag life.\n",
      "Dropped 83394 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  166.765.137\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 28448 records for detections before release time.\n",
      "Dropped 4757 records exceeding study period date and time.\n",
      "Dropped 88723 records where detection datetime exceeded tag life.\n",
      "Dropped 382396 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  166.765.138\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 10775 records for detections before release time.\n",
      "Dropped 55 records exceeding study period date and time.\n",
      "Dropped 2982 records where detection datetime exceeded tag life.\n",
      "Dropped 395944 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  166.765.139\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 19374 records for detections before release time.\n",
      "Dropped 61511 records exceeding study period date and time.\n",
      "Dropped 4200984 records where detection datetime exceeded tag life.\n",
      "Dropped 4389324 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  166.765.140\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 17739 records for detections before release time.\n",
      "Dropped 37 records exceeding study period date and time.\n",
      "Dropped 814 records where detection datetime exceeded tag life.\n",
      "Dropped 373524 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  166.765.141\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 8842 records for detections before release time.\n",
      "Dropped 2 records exceeding study period date and time.\n",
      "Dropped 51 records where detection datetime exceeded tag life.\n",
      "Dropped 1806178 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  166.765.142\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 12100 records for detections before release time.\n",
      "Dropped 2 records exceeding study period date and time.\n",
      "Dropped 106 records where detection datetime exceeded tag life.\n",
      "Dropped 423326 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  167.340.145\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 6838 records for detections before release time.\n",
      "Dropped 1 records exceeding study period date and time.\n",
      "Dropped 224 records where detection datetime exceeded tag life.\n",
      "Dropped 823 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  167.340.146\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 15232 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 108 records where detection datetime exceeded tag life.\n",
      "Dropped 113756 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  167.340.147\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 11973 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 36 records where detection datetime exceeded tag life.\n",
      "Dropped 73590 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  167.340.148\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 20069 records for detections before release time.\n",
      "Dropped 1 records exceeding study period date and time.\n",
      "Dropped 302 records where detection datetime exceeded tag life.\n",
      "Dropped 1948 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  167.340.149\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 37034 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 222 records where detection datetime exceeded tag life.\n",
      "Dropped 1050471 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  167.340.150\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 20704 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 29 records where detection datetime exceeded tag life.\n",
      "Dropped 494 duplicate MITAS and ORION records.\n",
      "No events available.\n",
      "Processing fish:  167.340.151\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 6336 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 90 records where detection datetime exceeded tag life.\n",
      "Dropped 209137 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  167.340.152\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 12810 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 27 records where detection datetime exceeded tag life.\n",
      "Dropped 774592 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  167.340.153\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 20179 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 54 records where detection datetime exceeded tag life.\n",
      "Dropped 320 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  167.340.154\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 3524 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 62 records where detection datetime exceeded tag life.\n",
      "Dropped 293 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  167.340.155\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 5717 records for detections before release time.\n",
      "Dropped 12 records exceeding study period date and time.\n",
      "Dropped 1228 records where detection datetime exceeded tag life.\n",
      "Dropped 3143 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  167.340.156\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 5190 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 125 records where detection datetime exceeded tag life.\n",
      "Dropped 43558 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  167.380.159\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 15619 records for detections before release time.\n",
      "Dropped 26949 records exceeding study period date and time.\n",
      "Dropped 1568740 records where detection datetime exceeded tag life.\n",
      "Dropped 1357820 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  167.380.160\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 17228 records for detections before release time.\n",
      "Dropped 6 records exceeding study period date and time.\n",
      "Dropped 1211 records where detection datetime exceeded tag life.\n",
      "Dropped 192639 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  167.380.161\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 20658 records for detections before release time.\n",
      "Dropped 2 records exceeding study period date and time.\n",
      "Dropped 183 records where detection datetime exceeded tag life.\n",
      "Dropped 210831 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  167.380.162\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 19947 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 106 records where detection datetime exceeded tag life.\n",
      "Dropped 13311 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  167.380.163\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 25338 records for detections before release time.\n",
      "Dropped 10 records exceeding study period date and time.\n",
      "Dropped 2749 records where detection datetime exceeded tag life.\n",
      "Dropped 4500 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  167.380.164\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 29819 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 190 records where detection datetime exceeded tag life.\n",
      "Dropped 1116 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  167.380.165\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 8788 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 287 records where detection datetime exceeded tag life.\n",
      "Dropped 35540 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  167.380.166\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 11239 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 284 records where detection datetime exceeded tag life.\n",
      "Dropped 738 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  167.380.167\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 13538 records for detections before release time.\n",
      "Dropped 2 records exceeding study period date and time.\n",
      "Dropped 171 records where detection datetime exceeded tag life.\n",
      "Dropped 219474 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  167.420.173\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 36816 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 216 records where detection datetime exceeded tag life.\n",
      "Dropped 792 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  167.420.174\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 32711 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 33 records where detection datetime exceeded tag life.\n",
      "Dropped 141769 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  167.420.175\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 30760 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 14 records where detection datetime exceeded tag life.\n",
      "Dropped 444916 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  167.420.176\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 47241 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 2 records where detection datetime exceeded tag life.\n",
      "Dropped 518251 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  167.420.177\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 49382 records for detections before release time.\n",
      "Dropped 2 records exceeding study period date and time.\n",
      "Dropped 39 records where detection datetime exceeded tag life.\n",
      "Dropped 223590 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  167.420.178\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 30933 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 156 records where detection datetime exceeded tag life.\n",
      "Dropped 1070 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  167.420.179\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 19360 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 68 records where detection datetime exceeded tag life.\n",
      "Dropped 312371 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  167.420.180\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 15927 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 45 records where detection datetime exceeded tag life.\n",
      "Dropped 34382 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  167.420.181\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 21420 records for detections before release time.\n",
      "Dropped 6 records exceeding study period date and time.\n",
      "Dropped 2856 records where detection datetime exceeded tag life.\n",
      "Dropped 797025 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  167.480.187\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 20618 records for detections before release time.\n",
      "Dropped 8 records exceeding study period date and time.\n",
      "Dropped 69162 records where detection datetime exceeded tag life.\n",
      "Dropped 283412 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  167.480.188\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 24194 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 56 records where detection datetime exceeded tag life.\n",
      "Dropped 52303 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  167.480.189\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 38187 records for detections before release time.\n",
      "Dropped 7 records exceeding study period date and time.\n",
      "Dropped 1259 records where detection datetime exceeded tag life.\n",
      "Dropped 423654 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  167.480.190\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 31295 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 26 records where detection datetime exceeded tag life.\n",
      "Dropped 629812 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  167.480.191\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 39152 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 148 records where detection datetime exceeded tag life.\n",
      "Dropped 285977 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  167.480.192\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 36848 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 74 records where detection datetime exceeded tag life.\n",
      "Dropped 215637 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  167.480.193\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 14021 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 12 records where detection datetime exceeded tag life.\n",
      "Dropped 241 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  167.480.194\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 20669 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 10 records where detection datetime exceeded tag life.\n",
      "Dropped 362 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  167.480.195\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 19785 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 236 records where detection datetime exceeded tag life.\n",
      "Dropped 519899 duplicate MITAS and ORION records.\n",
      "Producing events plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:610: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_detections = df.groupby([f\"{plot_field}_name\", \"date\"]).count().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"fish_id\")\n",
      "C:\\Users\\mcca512\\AppData\\Local\\Temp\\ipykernel_29232\\3467817052.py:618: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  plot_power = df.groupby([f\"{plot_field}_name\", \"date\"]).max().reset_index().pivot(f\"{plot_field}_name\", \"date\", \"signal_power\")\n"
     ]
    }
   ],
   "source": [
    "# target percentiles to evaluate for signal power threshold\n",
    "percentile_list = [0.80]\n",
    "\n",
    "for percentile in percentile_list:\n",
    "    \n",
    "    print(f\"Simulating percentile:  {percentile}\")\n",
    "\n",
    "    # all processed files\n",
    "    glob_path = os.path.join(parquet_raw_dir, \"*.parquet\")\n",
    "\n",
    "    # use all detections to generate a target percentile of signal power for each receiver\n",
    "    sig_df = duckdb.query(f\"\"\"SELECT receiver_id, quantile(signal_power, {percentile}) as power FROM '{glob_path}' GROUP BY receiver_id\"\"\").df()\n",
    "\n",
    "    # add detect site\n",
    "    sig_df[\"detect_site\"] = sig_df[\"receiver_id\"].map(reciever_to_detect_site_dict)\n",
    "\n",
    "    # change receiver id to site number\n",
    "    sig_df[\"site_number\"] = sig_df[\"receiver_id\"].map(receiver_to_site_number_dict)\n",
    "\n",
    "    # keep only valid receivers\n",
    "    sig_df = sig_df.loc[~sig_df[\"site_number\"].isna()]\n",
    "\n",
    "    # convert site ids to integers to facilitate lookup\n",
    "    sig_df[\"detect_site\"] = sig_df[\"detect_site\"].astype(int)\n",
    "    sig_df[\"site_number\"] = sig_df[\"site_number\"].astype(int)\n",
    "\n",
    "    # generate a dictionary of site id to its power threshold dictionary\n",
    "    site_to_power_percentile_dict = sig_df.set_index(\"site_number\")[\"power\"].to_dict()\n",
    "\n",
    "    # generate a data frame to display the signal power threshold per receiver\n",
    "    xd = {\"site_number\": [], \"signal_power\": [], \"percentile\": []}\n",
    "    for x in site_to_power_percentile_dict.keys():\n",
    "\n",
    "        xd[\"site_number\"].append(x)\n",
    "        xd[\"signal_power\"].append(site_to_power_percentile_dict[x])\n",
    "        xd[\"percentile\"].append(int(percentile * 100))\n",
    "\n",
    "    xf = pd.DataFrame(xd).sort_values(by=[\"site_number\"])\n",
    "    print(xf)\n",
    "    \n",
    "    # construct simulation name    \n",
    "    simulation = f\"mm_sum_2022_{int(percentile * 100)}-percentile-power\"\n",
    "\n",
    "    # generate fish list to process\n",
    "    fish_list = tagging_df[\"fish_id\"].unique()\n",
    "\n",
    "    for index, i in enumerate(fish_list):\n",
    "\n",
    "        print(f\"Processing fish:  {i}\")\n",
    "\n",
    "        ttdf, evdf = generate(fish_id=i, \n",
    "                              parquet_raw_dir=parquet_raw_dir,\n",
    "                              travel_time_template_dtypes=travel_time_template_dtypes,\n",
    "                              reciever_to_detect_site_dict=reciever_to_detect_site_dict,\n",
    "                              receiver_to_site_number_dict=receiver_to_site_number_dict,\n",
    "                              signal_power_threshold_dict=site_to_power_percentile_dict,\n",
    "                              detect_site_to_abbrev_dict=detect_site_to_abbrev_dict,\n",
    "                              detection_site_abbrev_list=detection_site_abbrev_list,\n",
    "                              detect_plot_name_dict=detect_plot_name_dict,\n",
    "                              site_plot_name_dict=site_plot_name_dict,\n",
    "                              simulation=simulation,\n",
    "                              tagging_df=tagging_df,\n",
    "                              beacon_df=beacon_df,\n",
    "                              project_end_date=project_end_date,\n",
    "                              max_tag_life_days=max_tag_life_days,\n",
    "                              use_events=True, \n",
    "                              consider_dam_operations=False,\n",
    "                              output_plot_directory=os.path.join(output_dir, f\"{simulation}/events/events_plots\"),\n",
    "                              generate_plots=True)\n",
    "\n",
    "        # save event detection by fish id CSV file\n",
    "        evdf.to_csv(os.path.join(output_dir, f\"{simulation}/events/events_by_fish_id/{i}.csv\"), index=False)\n",
    "\n",
    "        # add fish to travel time output\n",
    "        if index == 0:\n",
    "            travel_time_df = ttdf\n",
    "        else:\n",
    "            travel_time_df = pd.concat([travel_time_df, ttdf], axis=0)\n",
    "\n",
    "    # save travel time file\n",
    "    travel_time_df.to_csv(os.path.join(output_dir, f\"{simulation}/travel_time/travel_time.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2041fb88-d66b-4ad6-94f9-d7c5c06a3f8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598f84df-63fc-4bcb-9d91-07b81f6f6e09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0bf28d-a4c5-4586-9b06-ffb9bab793cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab661fa-ab8f-4d55-a41f-b0d80588c100",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299326bb-e241-4d26-9691-5ed197f4b8b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37279c1e-414d-435e-9349-8ec2352a2d5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00360fc8-594f-4f49-bb8f-b2d7358907be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5394185-754e-4fea-a81b-8a762668ed44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fish:  166.620.101\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 10918 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 67 records where detection datetime exceeded tag life.\n",
      "Dropped 1166485 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  166.620.102\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 8984 records for detections before release time.\n",
      "Dropped 2 records exceeding study period date and time.\n",
      "Dropped 215 records where detection datetime exceeded tag life.\n",
      "Dropped 552315 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  166.620.103\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 9955 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 53 records where detection datetime exceeded tag life.\n",
      "Dropped 157236 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  166.620.104\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 45563 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 40 records where detection datetime exceeded tag life.\n",
      "Dropped 1285332 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  166.620.105\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 25129 records for detections before release time.\n",
      "Dropped 2 records exceeding study period date and time.\n",
      "Dropped 214 records where detection datetime exceeded tag life.\n",
      "Dropped 147096 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  166.620.106\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 30017 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 816 records where detection datetime exceeded tag life.\n",
      "Dropped 407308 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  166.620.107\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 40413 records for detections before release time.\n",
      "Dropped 105419 records exceeding study period date and time.\n",
      "Dropped 6479802 records where detection datetime exceeded tag life.\n",
      "Dropped 5109295 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  166.620.108\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 31889 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 17 records where detection datetime exceeded tag life.\n",
      "Dropped 1274774 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  166.620.109\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 26265 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 4 records where detection datetime exceeded tag life.\n",
      "Dropped 1324 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  166.620.110\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 21778 records for detections before release time.\n",
      "Dropped 45 records exceeding study period date and time.\n",
      "Dropped 401472 records where detection datetime exceeded tag life.\n",
      "Dropped 1655845 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  166.620.111\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 19929 records for detections before release time.\n",
      "Dropped 10 records exceeding study period date and time.\n",
      "Dropped 1826487 records where detection datetime exceeded tag life.\n",
      "Dropped 4585721 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  166.620.112\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 16232 records for detections before release time.\n",
      "Dropped 34 records exceeding study period date and time.\n",
      "Dropped 2213 records where detection datetime exceeded tag life.\n",
      "Dropped 6126 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  166.740.116\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 10246 records for detections before release time.\n",
      "Dropped 3 records exceeding study period date and time.\n",
      "Dropped 503 records where detection datetime exceeded tag life.\n",
      "Dropped 2491270 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  166.740.117\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 8768 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 68 records where detection datetime exceeded tag life.\n",
      "Dropped 465039 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  166.740.118\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 9868 records for detections before release time.\n",
      "Dropped 13 records exceeding study period date and time.\n",
      "Dropped 76302 records where detection datetime exceeded tag life.\n",
      "Dropped 966866 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  166.740.119\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 43688 records for detections before release time.\n",
      "Dropped 29 records exceeding study period date and time.\n",
      "Dropped 431340 records where detection datetime exceeded tag life.\n",
      "Dropped 1838574 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  166.740.120\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 40469 records for detections before release time.\n",
      "Dropped 2 records exceeding study period date and time.\n",
      "Dropped 67 records where detection datetime exceeded tag life.\n",
      "Dropped 260429 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  166.740.121\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 18696 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 70 records where detection datetime exceeded tag life.\n",
      "Dropped 1101736 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  166.740.122\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 44299 records for detections before release time.\n",
      "Dropped 6 records exceeding study period date and time.\n",
      "Dropped 173 records where detection datetime exceeded tag life.\n",
      "Dropped 1972 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  166.740.123\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 20673 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 63 records where detection datetime exceeded tag life.\n",
      "Dropped 1561 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "No events available.\n",
      "Processing fish:  166.740.124\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 15683 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 16 records where detection datetime exceeded tag life.\n",
      "Dropped 136805 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  166.740.125\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 17214 records for detections before release time.\n",
      "Dropped 2 records exceeding study period date and time.\n",
      "Dropped 133 records where detection datetime exceeded tag life.\n",
      "Dropped 888 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  166.740.126\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 11917 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 9 records where detection datetime exceeded tag life.\n",
      "Dropped 240 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  166.740.127\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 6743 records for detections before release time.\n",
      "Dropped 2 records exceeding study period date and time.\n",
      "Dropped 19 records where detection datetime exceeded tag life.\n",
      "Dropped 269 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  166.765.131\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 13493 records for detections before release time.\n",
      "Dropped 2 records exceeding study period date and time.\n",
      "Dropped 149 records where detection datetime exceeded tag life.\n",
      "Dropped 150531 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  166.765.132\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 11302 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 88 records where detection datetime exceeded tag life.\n",
      "Dropped 453 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "No events available.\n",
      "Processing fish:  166.765.133\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 10739 records for detections before release time.\n",
      "Dropped 22 records exceeding study period date and time.\n",
      "Dropped 1358 records where detection datetime exceeded tag life.\n",
      "Dropped 670898 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  166.765.134\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 69709 records for detections before release time.\n",
      "Dropped 204 records exceeding study period date and time.\n",
      "Dropped 12162 records where detection datetime exceeded tag life.\n",
      "Dropped 2068452 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  166.765.135\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 48330 records for detections before release time.\n",
      "Dropped 2 records exceeding study period date and time.\n",
      "Dropped 335 records where detection datetime exceeded tag life.\n",
      "Dropped 1447 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "No events available.\n",
      "Processing fish:  166.765.136\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 12885 records for detections before release time.\n",
      "Dropped 4 records exceeding study period date and time.\n",
      "Dropped 92 records where detection datetime exceeded tag life.\n",
      "Dropped 83394 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  166.765.137\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 28448 records for detections before release time.\n",
      "Dropped 4757 records exceeding study period date and time.\n",
      "Dropped 88723 records where detection datetime exceeded tag life.\n",
      "Dropped 382396 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  166.765.138\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 10775 records for detections before release time.\n",
      "Dropped 55 records exceeding study period date and time.\n",
      "Dropped 2982 records where detection datetime exceeded tag life.\n",
      "Dropped 395944 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  166.765.139\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 19374 records for detections before release time.\n",
      "Dropped 61511 records exceeding study period date and time.\n",
      "Dropped 4200984 records where detection datetime exceeded tag life.\n",
      "Dropped 4389324 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  166.765.140\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 17739 records for detections before release time.\n",
      "Dropped 37 records exceeding study period date and time.\n",
      "Dropped 814 records where detection datetime exceeded tag life.\n",
      "Dropped 373524 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  166.765.141\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 8842 records for detections before release time.\n",
      "Dropped 2 records exceeding study period date and time.\n",
      "Dropped 51 records where detection datetime exceeded tag life.\n",
      "Dropped 1806178 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  166.765.142\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 12100 records for detections before release time.\n",
      "Dropped 2 records exceeding study period date and time.\n",
      "Dropped 106 records where detection datetime exceeded tag life.\n",
      "Dropped 423326 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  167.340.145\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 6838 records for detections before release time.\n",
      "Dropped 1 records exceeding study period date and time.\n",
      "Dropped 224 records where detection datetime exceeded tag life.\n",
      "Dropped 823 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  167.340.146\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 15232 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 108 records where detection datetime exceeded tag life.\n",
      "Dropped 113756 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  167.340.147\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 11973 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 36 records where detection datetime exceeded tag life.\n",
      "Dropped 73590 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  167.340.148\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 20069 records for detections before release time.\n",
      "Dropped 1 records exceeding study period date and time.\n",
      "Dropped 302 records where detection datetime exceeded tag life.\n",
      "Dropped 1948 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  167.340.149\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 37034 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 222 records where detection datetime exceeded tag life.\n",
      "Dropped 1050471 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  167.340.150\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 20704 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 29 records where detection datetime exceeded tag life.\n",
      "Dropped 494 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "No events available.\n",
      "Processing fish:  167.340.151\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 6336 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 90 records where detection datetime exceeded tag life.\n",
      "Dropped 209137 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  167.340.152\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 12810 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 27 records where detection datetime exceeded tag life.\n",
      "Dropped 774592 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  167.340.153\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 20179 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 54 records where detection datetime exceeded tag life.\n",
      "Dropped 320 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  167.340.154\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 3524 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 62 records where detection datetime exceeded tag life.\n",
      "Dropped 293 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  167.340.155\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 5717 records for detections before release time.\n",
      "Dropped 12 records exceeding study period date and time.\n",
      "Dropped 1228 records where detection datetime exceeded tag life.\n",
      "Dropped 3143 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  167.340.156\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 5190 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 125 records where detection datetime exceeded tag life.\n",
      "Dropped 43558 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  167.380.159\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 15619 records for detections before release time.\n",
      "Dropped 26949 records exceeding study period date and time.\n",
      "Dropped 1568740 records where detection datetime exceeded tag life.\n",
      "Dropped 1357820 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  167.380.160\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 17228 records for detections before release time.\n",
      "Dropped 6 records exceeding study period date and time.\n",
      "Dropped 1211 records where detection datetime exceeded tag life.\n",
      "Dropped 192639 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  167.380.161\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 20658 records for detections before release time.\n",
      "Dropped 2 records exceeding study period date and time.\n",
      "Dropped 183 records where detection datetime exceeded tag life.\n",
      "Dropped 210831 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  167.380.162\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 19947 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 106 records where detection datetime exceeded tag life.\n",
      "Dropped 13311 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  167.380.163\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 25338 records for detections before release time.\n",
      "Dropped 10 records exceeding study period date and time.\n",
      "Dropped 2749 records where detection datetime exceeded tag life.\n",
      "Dropped 4500 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  167.380.164\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 29819 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 190 records where detection datetime exceeded tag life.\n",
      "Dropped 1116 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  167.380.165\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 8788 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 287 records where detection datetime exceeded tag life.\n",
      "Dropped 35540 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  167.380.166\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 11239 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 284 records where detection datetime exceeded tag life.\n",
      "Dropped 738 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  167.380.167\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 13538 records for detections before release time.\n",
      "Dropped 2 records exceeding study period date and time.\n",
      "Dropped 171 records where detection datetime exceeded tag life.\n",
      "Dropped 219474 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  167.420.173\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 36816 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 216 records where detection datetime exceeded tag life.\n",
      "Dropped 792 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  167.420.174\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 32711 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 33 records where detection datetime exceeded tag life.\n",
      "Dropped 141769 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  167.420.175\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 30760 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 14 records where detection datetime exceeded tag life.\n",
      "Dropped 444916 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  167.420.176\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 47241 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 2 records where detection datetime exceeded tag life.\n",
      "Dropped 518251 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  167.420.177\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 49382 records for detections before release time.\n",
      "Dropped 2 records exceeding study period date and time.\n",
      "Dropped 39 records where detection datetime exceeded tag life.\n",
      "Dropped 223590 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  167.420.178\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 30933 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 156 records where detection datetime exceeded tag life.\n",
      "Dropped 1070 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  167.420.179\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 19360 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 68 records where detection datetime exceeded tag life.\n",
      "Dropped 312371 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  167.420.180\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 15927 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 45 records where detection datetime exceeded tag life.\n",
      "Dropped 34382 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  167.420.181\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 21420 records for detections before release time.\n",
      "Dropped 6 records exceeding study period date and time.\n",
      "Dropped 2856 records where detection datetime exceeded tag life.\n",
      "Dropped 797025 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  167.480.187\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 20618 records for detections before release time.\n",
      "Dropped 8 records exceeding study period date and time.\n",
      "Dropped 69162 records where detection datetime exceeded tag life.\n",
      "Dropped 283412 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  167.480.188\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 24194 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 56 records where detection datetime exceeded tag life.\n",
      "Dropped 52303 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  167.480.189\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 38187 records for detections before release time.\n",
      "Dropped 7 records exceeding study period date and time.\n",
      "Dropped 1259 records where detection datetime exceeded tag life.\n",
      "Dropped 423654 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  167.480.190\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 31295 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 26 records where detection datetime exceeded tag life.\n",
      "Dropped 629812 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  167.480.191\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 39152 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 148 records where detection datetime exceeded tag life.\n",
      "Dropped 285977 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  167.480.192\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 36848 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 74 records where detection datetime exceeded tag life.\n",
      "Dropped 215637 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  167.480.193\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 14021 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 12 records where detection datetime exceeded tag life.\n",
      "Dropped 241 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  167.480.194\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 20669 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 10 records where detection datetime exceeded tag life.\n",
      "Dropped 362 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "Processing fish:  167.480.195\n",
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 19785 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 236 records where detection datetime exceeded tag life.\n",
      "Dropped 519899 duplicate MITAS and ORION records.\n",
      "Producing clean plots...\n",
      "Producing events plots...\n",
      "CPU times: user 1h 46min 7s, sys: 8min 25s, total: 1h 54min 32s\n",
      "Wall time: 3h 22min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "simulation = f\"mm_sum_2022_{int(percentile * 100)}-percentile-power\"\n",
    "\n",
    "fish_list = tagging_df[\"fish_id\"].unique()\n",
    "\n",
    "for index, i in enumerate(fish_list):\n",
    "\n",
    "    print(f\"Processing fish:  {i}\")\n",
    "     \n",
    "    ttdf, evdf = generate(fish_id=i, \n",
    "                          parquet_raw_dir=parquet_raw_dir,\n",
    "                          travel_time_template_dtypes=travel_time_template_dtypes,\n",
    "                          reciever_to_detect_site_dict=reciever_to_detect_site_dict,\n",
    "                          receiver_to_site_number_dict=receiver_to_site_number_dict,\n",
    "                          signal_power_threshold_dict=site_to_power_percentile_dict,\n",
    "                          detect_site_to_abbrev_dict=detect_site_to_abbrev_dict,\n",
    "                          detection_site_abbrev_list=detection_site_abbrev_list,\n",
    "                          detect_plot_name_dict=detect_plot_name_dict,\n",
    "                          site_plot_name_dict=site_plot_name_dict,\n",
    "                          simulation=simulation,\n",
    "                          tagging_df=tagging_df,\n",
    "                          beacon_df=beacon_df,\n",
    "                          project_end_date=project_end_date,\n",
    "                          max_tag_life_days=max_tag_life_days,\n",
    "                          use_events=True, \n",
    "                          consider_dam_operations=False,\n",
    "                          output_plot_directory=os.path.join(output_dir, f\"{simulation}/events/events_plots\"),\n",
    "                          generate_plots=True)\n",
    "    \n",
    "    evdf.to_csv(os.path.join(output_dir, f\"{simulation}/events/events_by_fish_id/{i}.csv\"), index=False)\n",
    "    \n",
    "    if index == 0:\n",
    "        travel_time_df = ttdf\n",
    "    else:\n",
    "        travel_time_df = pd.concat([travel_time_df, ttdf], axis=0)\n",
    "        \n",
    "travel_time_df.to_csv(os.path.join(output_dir, f\"{simulation}/travel_time/travel_time.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd1b59b-c0b2-46eb-895e-2d7fa1d87391",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b9a0d4-8ed9-453f-821a-d484890aec83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dc35d6-4dca-4d30-b68c-0caa3f90ac24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce2264d-4fb4-49c6-9340-c43d3f211d8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a740f0e8-d1cf-441e-851e-d3ccc50808dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7bb4835-dfd4-4cd9-8819-0ac2c39fa9a2",
   "metadata": {},
   "source": [
    "# Start here with new fish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "02a8bc69-e240-4d3e-947b-8248ca323461",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fish_id = \"166.620.101\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108dba06-4076-4832-bbb1-7473f29f71e6",
   "metadata": {},
   "source": [
    "## Filter raw data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "698458a9-8806-4429-b3c7-82aeb3f5adf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 0 records for fish not in tagging file.\n",
      "Dropped 8048 records for detections before release time.\n",
      "Dropped 0 records exceeding study period date and time.\n",
      "Dropped 19355 duplicate MITAS and ORION records.\n",
      "CPU times: user 8.69 s, sys: 1.54 s, total: 10.2 s\n",
      "Wall time: 4.36 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# get path to glob all raw parquet files\n",
    "glob_path = os.path.join(parquet_raw_dir, \"*.parquet\")\n",
    "\n",
    "# fish_iterator = tqdm([fish_array[3]])\n",
    "\n",
    "fish_iterator = [test_fish_id]\n",
    "\n",
    "for i in fish_iterator:\n",
    "    \n",
    "    df = filter_raw_data(glob_path,\n",
    "                         reciever_to_detect_site_dict=reciever_to_detect_site_dict,\n",
    "                         receiver_to_site_number_dict=receiver_to_site_number_dict,\n",
    "                         tagging_df=tagging_df,\n",
    "                         project_end_date=project_end_date)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0fadb8-f057-4911-a8b1-e120d66b7b82",
   "metadata": {},
   "source": [
    "## Create lag/lead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5ab1d407-c811-40ef-8fdb-198f633b9755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.89 s, sys: 397 ms, total: 2.28 s\n",
      "Wall time: 2.29 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df = generate_lag_lead_records(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d7e4a9-21d9-484f-a318-7b85ec00ac0f",
   "metadata": {},
   "source": [
    "## Create events with no dam operations considered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0cbfb057-62dc-4246-98fd-c0e45d7eb420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of detection sites per hits per second condition\n",
    "cond_one = beacon_df.loc[beacon_df[\"hits_seconds_run\"] == \"3_60\"][\"detect_site\"].to_list()\n",
    "cond_two = beacon_df.loc[beacon_df[\"hits_seconds_run\"] == \"2_120\"][\"detect_site\"].to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8bee3626-0f2a-4f9f-86d2-48d52b53475d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.31 s, sys: 476 ms, total: 2.78 s\n",
      "Wall time: 2.79 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# create events per condition\n",
    "dfa = create_events(df, hits=3, seconds=60, detection_sites=cond_one)\n",
    "dfb = create_events(df, hits=2, seconds=120, detection_sites=cond_two)\n",
    "\n",
    "# merge output\n",
    "events_nops = pd.concat([dfa, dfb])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5939b49b-5c80-4582-b96a-64a5c6fc8770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal power threshold for 95th percentile:  -58.0\n"
     ]
    }
   ],
   "source": [
    "# use the 95th percentile of signal power to filter events where 95% of all records fall under\n",
    "minimum_signal_power = events_nops[\"signal_power\"].quantile(q=0.95)\n",
    "\n",
    "print(f\"Signal power threshold for 95th percentile:  {minimum_signal_power}\")\n",
    "\n",
    "# filter events by threshold\n",
    "events_nops = events_nops.loc[events_nops[\"signal_power\"] >= minimum_signal_power]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6047d7cc-3e07-4202-bdc3-d344084c3ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = events_nops.copy()\n",
    "\n",
    "# df[\"date\"] = df[\"date_time\"].dt.date\n",
    "\n",
    "df[\"date\"] = df[\"date_time\"].dt.round(\"H\").dt.strftime('%m-%d %H:00:00')\n",
    "\n",
    "df = df.loc[df[\"signal_power\"] >= minimum_signal_power]\n",
    "\n",
    "plot_detections = df.groupby([\"detect_site\", \"date\"]).count().reset_index().pivot(\"detect_site\", \"date\", \"fish_id\")\n",
    "\n",
    "# more negative power is weaker; closer to 0 is more powerful\n",
    "plot_power = df.groupby([\"detect_site\", \"date\"]).max().reset_index().pivot(\"detect_site\", \"date\", \"signal_power\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "da33a579-ec44-4591-834c-23e54972d07c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots(figsize=(25, 4))\n",
    "\n",
    "# g = sns.heatmap(plot_detections, annot=False, linewidths=.5, ax=ax)\n",
    "g = sns.heatmap(plot_detections, annot=False, ax=ax, cmap=\"vlag\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1af864e8-abb1-4059-a80c-66c9439b8457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots(figsize=(25, 3))\n",
    "\n",
    "g = sns.heatmap(plot_power, annot=False, cmap=\"vlag\", ax=ax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd074d36-6feb-446c-8ec4-3650ae897d2e",
   "metadata": {},
   "source": [
    "## format events for use in travel time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d926a4f1-c40f-4109-b2b6-c622eedc5227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 57.1 ms, sys: 3.22 ms, total: 60.4 ms\n",
      "Wall time: 59.7 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(14, 5)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# dictionary of detetion sites to travel time file abbreviation\n",
    "detect_site_to_abbrev_dict = {1: \"sw\",\n",
    "                              2: \"e1\",\n",
    "                              3: \"e2\",\n",
    "                              4: \"l1\",\n",
    "                              5: \"l2\",\n",
    "                              6: \"l3\",\n",
    "                              7: \"ps\"}\n",
    "\n",
    "\n",
    "# generate last event time for each detection site\n",
    "events_nops_last = events_nops.groupby([\"fish_id\", \"grouping\", \"detect_site\"])[\"date_time\"].max().reset_index()\n",
    "events_nops_last[\"site_abbrev\"] = events_nops_last[\"detect_site\"].map(detect_site_to_abbrev_dict).str.lower() + \"_l\"\n",
    "\n",
    "# generate first event time for each detection site\n",
    "events_nops_first = events_nops.groupby([\"fish_id\", \"grouping\", \"detect_site\"])[\"date_time\"].min().reset_index()\n",
    "events_nops_first[\"site_abbrev\"] = events_nops_first[\"detect_site\"].map(detect_site_to_abbrev_dict).str.lower() + \"_f\"\n",
    "\n",
    "# combine\n",
    "events_nops_tt = pd.concat([events_nops_first, events_nops_last])\n",
    "\n",
    "events_nops_tt.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "937ebb07-67b0-4c59-bec5-486cb83483a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fish_id</th>\n",
       "      <th>grouping</th>\n",
       "      <th>detect_site</th>\n",
       "      <th>date_time</th>\n",
       "      <th>site_abbrev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>167.340.152</td>\n",
       "      <td>3_60</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-07-06 16:27:53</td>\n",
       "      <td>sw_f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>167.340.152</td>\n",
       "      <td>3_60</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-07-21 20:25:57</td>\n",
       "      <td>sw_l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>167.340.152</td>\n",
       "      <td>2_120</td>\n",
       "      <td>2</td>\n",
       "      <td>2022-07-07 16:38:36</td>\n",
       "      <td>e1_f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>167.340.152</td>\n",
       "      <td>2_120</td>\n",
       "      <td>2</td>\n",
       "      <td>2022-07-21 20:29:26</td>\n",
       "      <td>e1_l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>167.340.152</td>\n",
       "      <td>2_120</td>\n",
       "      <td>3</td>\n",
       "      <td>2022-07-07 16:49:55</td>\n",
       "      <td>e2_f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>167.340.152</td>\n",
       "      <td>2_120</td>\n",
       "      <td>3</td>\n",
       "      <td>2022-07-21 20:35:49</td>\n",
       "      <td>e2_l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>167.340.152</td>\n",
       "      <td>2_120</td>\n",
       "      <td>4</td>\n",
       "      <td>2022-07-09 18:38:31</td>\n",
       "      <td>l1_f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>167.340.152</td>\n",
       "      <td>2_120</td>\n",
       "      <td>4</td>\n",
       "      <td>2022-07-21 20:37:52</td>\n",
       "      <td>l1_l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>167.340.152</td>\n",
       "      <td>2_120</td>\n",
       "      <td>5</td>\n",
       "      <td>2022-07-09 18:42:07</td>\n",
       "      <td>l2_f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>167.340.152</td>\n",
       "      <td>2_120</td>\n",
       "      <td>5</td>\n",
       "      <td>2022-07-21 20:38:13</td>\n",
       "      <td>l2_l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>167.340.152</td>\n",
       "      <td>2_120</td>\n",
       "      <td>6</td>\n",
       "      <td>2022-07-21 17:38:49</td>\n",
       "      <td>l3_f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>167.340.152</td>\n",
       "      <td>2_120</td>\n",
       "      <td>6</td>\n",
       "      <td>2022-07-21 20:39:07</td>\n",
       "      <td>l3_l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>167.340.152</td>\n",
       "      <td>2_120</td>\n",
       "      <td>7</td>\n",
       "      <td>2022-07-21 17:50:17</td>\n",
       "      <td>ps_f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>167.340.152</td>\n",
       "      <td>2_120</td>\n",
       "      <td>7</td>\n",
       "      <td>2022-08-03 08:14:40</td>\n",
       "      <td>ps_l</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fish_id grouping  detect_site           date_time site_abbrev\n",
       "6  167.340.152     3_60            1 2022-07-06 16:27:53        sw_f\n",
       "6  167.340.152     3_60            1 2022-07-21 20:25:57        sw_l\n",
       "0  167.340.152    2_120            2 2022-07-07 16:38:36        e1_f\n",
       "0  167.340.152    2_120            2 2022-07-21 20:29:26        e1_l\n",
       "1  167.340.152    2_120            3 2022-07-07 16:49:55        e2_f\n",
       "1  167.340.152    2_120            3 2022-07-21 20:35:49        e2_l\n",
       "2  167.340.152    2_120            4 2022-07-09 18:38:31        l1_f\n",
       "2  167.340.152    2_120            4 2022-07-21 20:37:52        l1_l\n",
       "3  167.340.152    2_120            5 2022-07-09 18:42:07        l2_f\n",
       "3  167.340.152    2_120            5 2022-07-21 20:38:13        l2_l\n",
       "4  167.340.152    2_120            6 2022-07-21 17:38:49        l3_f\n",
       "4  167.340.152    2_120            6 2022-07-21 20:39:07        l3_l\n",
       "5  167.340.152    2_120            7 2022-07-21 17:50:17        ps_f\n",
       "5  167.340.152    2_120            7 2022-08-03 08:14:40        ps_l"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events_nops_tt.sort_values(by=\"detect_site\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51c89f9-1f92-4213-905c-ab64f4e2f39b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "023fe617-0bf0-4cf6-89f1-2f6dbe7c2f80",
   "metadata": {},
   "source": [
    "# The following is in-development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1a2a8b-0121-40c8-9d55-ba66df18421d",
   "metadata": {},
   "source": [
    "## generate travel time with no ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "95e3682e-073b-4f70-8616-9015a14a8f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of data types for the travel time data frame\n",
    "travel_time_template_dtypes = {\n",
    "    # \"fish_id\": str,\n",
    "    \"pit_code\": str,\n",
    "    \"rel_name\": str,\n",
    "    \"lot\": int,\n",
    "    \"srr\": str,\n",
    "    \"act_datetime\": \"datetime64[ns]\",\n",
    "    \"release_datetime\": \"datetime64[ns]\",\n",
    "    \"hole\": str,\n",
    "    \"subhole\": str,\n",
    "    \"sw\": int,\n",
    "    \"e1\": int,\n",
    "    \"e2\": int,\n",
    "    \"l1\": int,\n",
    "    \"l2\": int,\n",
    "    \"l3\": int,\n",
    "    \"ps\": int,\n",
    "    \"sw_f\": \"datetime64[ns]\",\n",
    "    \"sw_l\": \"datetime64[ns]\",\n",
    "    \"e1_f\": \"datetime64[ns]\",\n",
    "    \"e1_l\": \"datetime64[ns]\",\n",
    "    \"e2_f\": \"datetime64[ns]\",\n",
    "    \"e2_l\": \"datetime64[ns]\",\n",
    "    \"l1_f\": \"datetime64[ns]\",\n",
    "    \"l1_l\": \"datetime64[ns]\",\n",
    "    \"l2_f\": \"datetime64[ns]\",\n",
    "    \"l2_l\": \"datetime64[ns]\",\n",
    "    \"l3_f\": \"datetime64[ns]\",\n",
    "    \"l3_l\": \"datetime64[ns]\",\n",
    "    \"ps_f\": \"datetime64[ns]\",\n",
    "    \"ps_l\": \"datetime64[ns]\",\n",
    "    \"rel_weir_time_s\": int,\n",
    "    \"pool_stage\": str,\n",
    "    \"censor\": int,\n",
    "    \"altered\": int,\n",
    "    \"mort_xlat\": int,\n",
    "    \"release_stage\": str,\n",
    "    \"comments\": str\n",
    "}\n",
    "\n",
    "# build a dictionary of field with empty data\n",
    "travel_time_template_dict = {i: [] for i in travel_time_template_dtypes.keys()}\n",
    "\n",
    "# generate travel time template\n",
    "travel_time_template = pd.DataFrame(travel_time_template_dict).astype(travel_time_template_dtypes)\n",
    "\n",
    "# add fish ids to the travel time file\n",
    "travel_time_template[\"fish_id\"] = tagging_df.index\n",
    "\n",
    "# set template site designation to 0 \n",
    "detection_site_abbrev_list = [\"sw\", \"e1\", \"e2\", \"l1\", \"l2\", \"l3\", \"ps\"]\n",
    "travel_time_template[detection_site_abbrev_list] = 0\n",
    "\n",
    "# generate a list of detection site first and last columns in order\n",
    "detection_site_time_columns = []\n",
    "for i in detection_site_abbrev_list:\n",
    "    detection_site_time_columns.append(f\"{i}_f\")\n",
    "    detection_site_time_columns.append(f\"{i}_l\")\n",
    "\n",
    "# sort by fish id\n",
    "travel_time_template.sort_values(by=[\"fish_id\"], inplace=True)\n",
    "\n",
    "# set index to fish id\n",
    "travel_time_template.set_index(\"fish_id\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "654a6647-03ba-4693-a726-8979dafb7e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_nops_tt_layout = pd.pivot_table(events_nops_tt,\n",
    "                                       values=\"date_time\",\n",
    "                                       index=[\"fish_id\"],\n",
    "                                       columns=[\"site_abbrev\"]).rename_axis(None, axis=1)\n",
    "\n",
    "# add empty columns to make full travel time input\n",
    "events_nops_tt_layout_columns = events_nops_tt_layout.columns\n",
    "\n",
    "for i in travel_time_template_dtypes.keys():\n",
    "    \n",
    "    if i not in events_nops_tt_layout_columns:\n",
    "        events_nops_tt_layout[i] = None\n",
    "\n",
    "# reorder columns\n",
    "events_nops_tt_layout = events_nops_tt_layout[travel_time_template_dtypes.keys()]\n",
    "\n",
    "events_nops_tt_layout.to_csv(\"/Users/d3y010/Desktop/template_no-ops.csv\", index=True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cda8d481-a1e5-41e5-8cc2-4c1d0947efe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_ops = events_nops.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8f3041f0-962a-4d2d-880c-2782de4d3bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update template fields for each detection site where an event was logged regardless of whether or not the fish passed the site\n",
    "x = events_ops.set_index(\"fish_id\")[\"detect_site\"].map({i: detect_site_to_abbrev_dict[i].lower() for i in detect_site_to_abbrev_dict.keys()}).reset_index()\n",
    "\n",
    "x[\"detected\"] = 1\n",
    "\n",
    "detect_designation = pd.pivot_table(x, values=\"detected\", index=\"fish_id\", columns=\"detect_site\", fill_value=0).rename_axis(None, axis=1)\n",
    "\n",
    "# update the template data frame with the new data\n",
    "travel_time_template.update(detect_designation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ccfde186-74bb-4100-a191-a480cefc1259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build release name needed in travel time file\n",
    "tagging_df[\"rel_name\"] = tagging_df[\"release_location_xlat\"] + \"_\" + tagging_df[\"srr\"]\n",
    "\n",
    "# extract that tagging file information needed for the travel time data frame\n",
    "tagging_for_tt = tagging_df[[\"pit_code\", \"rel_name\", \"srr\", \"tag_activation_date_pst\", \"tag_release_date_pst\", \"mort_xlat\"]].copy()\n",
    "\n",
    "# rename columns to what is expected in the travel time data frame\n",
    "tagging_for_tt.rename(columns={\"tag_activation_date_pst\": \"act_datetime\", \n",
    "                               \"tag_release_date_pst\": \"release_datetime\"},\n",
    "                      inplace=True)\n",
    "\n",
    "# update the template data frame with the new data\n",
    "travel_time_template.update(tagging_for_tt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1c23684b-feb3-49d2-a306-7e1e0b054456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pit_code</th>\n",
       "      <th>rel_name</th>\n",
       "      <th>lot</th>\n",
       "      <th>srr</th>\n",
       "      <th>act_datetime</th>\n",
       "      <th>release_datetime</th>\n",
       "      <th>hole</th>\n",
       "      <th>subhole</th>\n",
       "      <th>sw</th>\n",
       "      <th>e1</th>\n",
       "      <th>...</th>\n",
       "      <th>l3_l</th>\n",
       "      <th>ps_f</th>\n",
       "      <th>ps_l</th>\n",
       "      <th>rel_weir_time_s</th>\n",
       "      <th>pool_stage</th>\n",
       "      <th>censor</th>\n",
       "      <th>altered</th>\n",
       "      <th>mort_xlat</th>\n",
       "      <th>release_stage</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fish_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3DD.003BD5543A</td>\n",
       "      <td>R1_stuck_11W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11W</td>\n",
       "      <td>2022-06-21 16:16:01</td>\n",
       "      <td>2022-06-22 12:32:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3DD.003BD55446</td>\n",
       "      <td>R1_stuck_11W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11W</td>\n",
       "      <td>2022-06-21 16:13:55</td>\n",
       "      <td>2022-06-22 12:32:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3DD.003BD55460</td>\n",
       "      <td>R1_stuck_11W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11W</td>\n",
       "      <td>2022-06-21 16:15:49</td>\n",
       "      <td>2022-06-22 12:32:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3DD.003BD5544C</td>\n",
       "      <td>R2_fpf_11W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11W</td>\n",
       "      <td>2022-06-21 16:28:37</td>\n",
       "      <td>2022-06-26 08:30:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3DD.003BD55440</td>\n",
       "      <td>R1_stuck_11W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11W</td>\n",
       "      <td>2022-06-21 16:26:59</td>\n",
       "      <td>2022-06-24 11:02:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>3DD.003BD55461</td>\n",
       "      <td>R3_stewart_11W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11W</td>\n",
       "      <td>2022-06-24 15:44:37</td>\n",
       "      <td>2022-06-27 14:20:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>3DD.003BD5541D</td>\n",
       "      <td>R3_stewart_11W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11W</td>\n",
       "      <td>2022-06-24 15:46:29</td>\n",
       "      <td>2022-06-27 14:20:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>3DD.003BD5543F</td>\n",
       "      <td>R3_stewart_11W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11W</td>\n",
       "      <td>2022-06-27 19:06:38</td>\n",
       "      <td>2022-06-28 11:52:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>3DD.003BD5544F</td>\n",
       "      <td>R3_stewart_11W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11W</td>\n",
       "      <td>2022-06-27 19:05:54</td>\n",
       "      <td>2022-06-28 11:52:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>3DD.003BD55463</td>\n",
       "      <td>R3_stewart_11W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11W</td>\n",
       "      <td>2022-06-27 19:11:18</td>\n",
       "      <td>2022-06-28 11:52:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               pit_code        rel_name  lot  srr        act_datetime  \\\n",
       "fish_id                                                                 \n",
       "0        3DD.003BD5543A    R1_stuck_11W  NaN  11W 2022-06-21 16:16:01   \n",
       "1        3DD.003BD55446    R1_stuck_11W  NaN  11W 2022-06-21 16:13:55   \n",
       "2        3DD.003BD55460    R1_stuck_11W  NaN  11W 2022-06-21 16:15:49   \n",
       "3        3DD.003BD5544C      R2_fpf_11W  NaN  11W 2022-06-21 16:28:37   \n",
       "4        3DD.003BD55440    R1_stuck_11W  NaN  11W 2022-06-21 16:26:59   \n",
       "...                 ...             ...  ...  ...                 ...   \n",
       "70       3DD.003BD55461  R3_stewart_11W  NaN  11W 2022-06-24 15:44:37   \n",
       "71       3DD.003BD5541D  R3_stewart_11W  NaN  11W 2022-06-24 15:46:29   \n",
       "72       3DD.003BD5543F  R3_stewart_11W  NaN  11W 2022-06-27 19:06:38   \n",
       "73       3DD.003BD5544F  R3_stewart_11W  NaN  11W 2022-06-27 19:05:54   \n",
       "74       3DD.003BD55463  R3_stewart_11W  NaN  11W 2022-06-27 19:11:18   \n",
       "\n",
       "           release_datetime hole subhole  sw  e1  ...  l3_l  ps_f  ps_l  \\\n",
       "fish_id                                           ...                     \n",
       "0       2022-06-22 12:32:00  NaN     NaN   0   0  ...   NaT   NaT   NaT   \n",
       "1       2022-06-22 12:32:00  NaN     NaN   0   0  ...   NaT   NaT   NaT   \n",
       "2       2022-06-22 12:32:00  NaN     NaN   0   0  ...   NaT   NaT   NaT   \n",
       "3       2022-06-26 08:30:00  NaN     NaN   0   0  ...   NaT   NaT   NaT   \n",
       "4       2022-06-24 11:02:00  NaN     NaN   0   0  ...   NaT   NaT   NaT   \n",
       "...                     ...  ...     ...  ..  ..  ...   ...   ...   ...   \n",
       "70      2022-06-27 14:20:00  NaN     NaN   0   0  ...   NaT   NaT   NaT   \n",
       "71      2022-06-27 14:20:00  NaN     NaN   0   0  ...   NaT   NaT   NaT   \n",
       "72      2022-06-28 11:52:00  NaN     NaN   0   0  ...   NaT   NaT   NaT   \n",
       "73      2022-06-28 11:52:00  NaN     NaN   0   0  ...   NaT   NaT   NaT   \n",
       "74      2022-06-28 11:52:00  NaN     NaN   0   0  ...   NaT   NaT   NaT   \n",
       "\n",
       "         rel_weir_time_s  pool_stage censor altered mort_xlat release_stage  \\\n",
       "fish_id                                                                       \n",
       "0                    NaN         NaN    NaN     NaN       0.0           NaN   \n",
       "1                    NaN         NaN    NaN     NaN       0.0           NaN   \n",
       "2                    NaN         NaN    NaN     NaN       0.0           NaN   \n",
       "3                    NaN         NaN    NaN     NaN       0.0           NaN   \n",
       "4                    NaN         NaN    NaN     NaN       0.0           NaN   \n",
       "...                  ...         ...    ...     ...       ...           ...   \n",
       "70                   NaN         NaN    NaN     NaN       0.0           NaN   \n",
       "71                   NaN         NaN    NaN     NaN       0.0           NaN   \n",
       "72                   NaN         NaN    NaN     NaN       0.0           NaN   \n",
       "73                   NaN         NaN    NaN     NaN       0.0           NaN   \n",
       "74                   NaN         NaN    NaN     NaN       0.0           NaN   \n",
       "\n",
       "        comments  \n",
       "fish_id           \n",
       "0            NaN  \n",
       "1            NaN  \n",
       "2            NaN  \n",
       "3            NaN  \n",
       "4            NaN  \n",
       "...          ...  \n",
       "70           NaN  \n",
       "71           NaN  \n",
       "72           NaN  \n",
       "73           NaN  \n",
       "74           NaN  \n",
       "\n",
       "[75 rows x 36 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "travel_time_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe1485f-85c6-4879-82cd-04c0b614c742",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d615c088-b6a8-4050-910b-5f400aa80937",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "424bcf57-57ce-49bb-b795-6472372a5760",
   "metadata": {},
   "source": [
    "**NOTE**: apply pool and release stage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403df6cf-1959-4fb4-ace2-7843701a5c67",
   "metadata": {},
   "source": [
    "### route of passage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2d14e3a7-0d8d-4fc9-81f1-b3c8ac39fa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hole_dict = {4: \"SW4\",\n",
    "             5: \"SP2\",\n",
    "             6: \"SP3\",\n",
    "             7: \"SP4\",\n",
    "             9: \"PS2\",\n",
    "             10: \"PS1\"}\n",
    "\n",
    "subhole_dict = {4: \"WEIR\",\n",
    "                5: \"NON-WEIR\",\n",
    "                6: \"NON-WEIR\",\n",
    "                7: \"NON-WEIR\",\n",
    "                9: \"TURBINE\",\n",
    "                10: \"TURBINE\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9f60eab8-6409-4d16-a2e2-e1248ea1d1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for fish with a dam last with or without a downstream event\n",
    "dam_last_tt_fish = travel_time_template[[\"dam_l\"]].loc[~travel_time_template[[\"dam_l\"]][\"dam_l\"].isna()]\n",
    "\n",
    "route_dam_last = events_ops.loc[(events_ops[\"fish_id\"].isin(dam_last_tt_fish.index)) & \n",
    "                                (events_ops[\"date_time\"].isin(dam_last_tt_fish[\"dam_l\"])) &\n",
    "                                (events_ops[\"detect_site\"] == dam_detect_site)].sort_values(by=[\"fish_id\"]).reset_index(drop=True)[[\"fish_id\", \"site_number\"]].copy()\n",
    "\n",
    "# add hole\n",
    "route_dam_last[\"hole\"] = route_dam_last[\"site_number\"].map(hole_dict)\n",
    "\n",
    "# add subhole\n",
    "route_dam_last[\"subhole\"] = route_dam_last[\"site_number\"].map(subhole_dict)\n",
    "\n",
    "# # drop site number\n",
    "# route_dam_last.drop(columns=[\"site_number\"], inplace=True)\n",
    "\n",
    "route_dam_last.set_index(\"fish_id\", inplace=True)\n",
    "\n",
    "route_dam_hole_dict = route_dam_last[\"hole\"].to_dict()\n",
    "route_dam_subhole_dict = route_dam_last[\"subhole\"].to_dict()\n",
    "\n",
    "travel_time_template_hole = travel_time_template[\"hole\"].to_dict()\n",
    "travel_time_template_hole.update(route_dam_hole_dict)\n",
    "travel_time_template[\"hole\"] = travel_time_template.index.map(travel_time_template_hole)\n",
    "\n",
    "\n",
    "travel_time_template_subhole = travel_time_template[\"subhole\"].to_dict()\n",
    "travel_time_template_subhole.update(route_dam_subhole_dict)\n",
    "travel_time_template[\"subhole\"] = travel_time_template.index.map(travel_time_template_subhole)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cbd99bba-58ef-49f5-88e3-2e23f01a561e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 2)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for fish with no dam last but a downstream event\n",
    "forebay_downstream_sites = ['dam', 'tw', 'egr', 'prm', 'leb', 'srs', 'coi', 'wil']\n",
    "\n",
    "route_fby_only = travel_time_template.loc[travel_time_template[\"fby\"] == 1][forebay_downstream_sites].copy()\n",
    "\n",
    "route_fby_only[\"hole\"] = np.where(route_fby_only[forebay_downstream_sites].sum(axis=1) == 0, \"FBY\", \"NA\")\n",
    "\n",
    "route_fby_only = route_fby_only.loc[route_fby_only[\"hole\"] == \"FBY\"]\n",
    "\n",
    "route_fby_only[\"subhole\"] = \"NaN\"\n",
    "\n",
    "route_fby_only.drop(columns=['dam', 'tw', 'egr', 'prm', 'leb', 'srs', 'coi', 'wil'], inplace=True)\n",
    "\n",
    "travel_time_template.update(route_fby_only)\n",
    "\n",
    "route_fby_only.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a95f4d8d-0800-48c7-9fc0-2b0cba5feada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# travel_time_template['gp_fby_f'] = pd.to_datetime(travel_time_template['gp_fby_f'])\n",
    "# travel_time_template['gp_fby_l'] = pd.to_datetime(travel_time_template['gp_fby_l'])\n",
    "# travel_time_template['gp_tw_f'] = pd.to_datetime(travel_time_template['gp_tw_f'])\n",
    "# travel_time_template['gp_tw_l'] = pd.to_datetime(travel_time_template['gp_tw_l'])\n",
    "# travel_time_template['sun_f'] = pd.to_datetime(travel_time_template['sun_f'])\n",
    "# travel_time_template['sun_l'] = pd.to_datetime(travel_time_template['sun_l'])\n",
    "# travel_time_template['fby_f'] = pd.to_datetime(travel_time_template['fby_f'])\n",
    "# travel_time_template['fby_l'] = pd.to_datetime(travel_time_template['fby_l'])\n",
    "# travel_time_template['bc_f'] = pd.to_datetime(travel_time_template['bc_f'])\n",
    "# travel_time_template['bc_l'] = pd.to_datetime(travel_time_template['bc_l'])\n",
    "# travel_time_template['dam_f'] = pd.to_datetime(travel_time_template['dam_f'])\n",
    "# travel_time_template['dam_l'] = pd.to_datetime(travel_time_template['dam_l'])\n",
    "# travel_time_template['tw_f'] = pd.to_datetime(travel_time_template['tw_f'])\n",
    "# travel_time_template['tw_l'] = pd.to_datetime(travel_time_template['tw_l'])\n",
    "# travel_time_template['egr_f'] = pd.to_datetime(travel_time_template['egr_f'])\n",
    "# travel_time_template['egr_l'] = pd.to_datetime(travel_time_template['egr_l'])\n",
    "# travel_time_template['prm_f'] = pd.to_datetime(travel_time_template['prm_f'])\n",
    "# travel_time_template['prm_l'] = pd.to_datetime(travel_time_template['prm_l'])\n",
    "# travel_time_template['leb_f'] = pd.to_datetime(travel_time_template['leb_f'])\n",
    "# travel_time_template['leb_l'] = pd.to_datetime(travel_time_template['leb_l'])\n",
    "# travel_time_template['srs_f'] = pd.to_datetime(travel_time_template['srs_f'])\n",
    "# travel_time_template['srs_l'] = pd.to_datetime(travel_time_template['srs_l'])\n",
    "# travel_time_template['coi_f'] = pd.to_datetime(travel_time_template['coi_f'])\n",
    "# travel_time_template['coi_l'] = pd.to_datetime(travel_time_template['coi_l'])\n",
    "# travel_time_template['wil_f'] = pd.to_datetime(travel_time_template['wil_f'])\n",
    "# travel_time_template['wil_l'] = pd.to_datetime(travel_time_template['wil_l'])\n",
    "\n",
    "\n",
    "# travel_time_template.to_csv(\"/Users/d3y010/Desktop/template_ops.csv\", index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f238da58-c497-4e6d-99eb-7938bbcc1d68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59cda20-f6a9-4bb5-919f-91b056c65979",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8a8c34-1a9c-45f0-b4f5-4d9eecb293d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5f78b5-76f3-4936-99e3-b4fed370cc7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f946cea4-502f-4a00-a220-4f7e80725dff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e04873-996a-46c7-b32b-792781fdcb3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69086a75-5115-40e7-a025-709a12370027",
   "metadata": {},
   "source": [
    "- are we setting bc last to dam last?\n",
    "    - pupose of BC arrays (underwater antennas) was to use them to produce a route of passage if there was none (not so much to define the timestamp)\n",
    "    - bc last is always dam last when dam last exists\n",
    "    - Options:  1) remove BC arrays from travel time file, 2) or keep them;\n",
    "    \n",
    "- fby last is always dam last if exists\n",
    "- can fby first be > then fby l? or bc\"\n",
    "- for predation: do you want me to screen the FBY detections after downstream? from event validation?  [YES]\n",
    "- what does 1, 0 actually mean for sites?  is it passage or just detection?  Should these be based off of events with no ops considered?\n",
    "    - 1 means detected at every site but dam; where 1 means passed at dam and bc (should use dam considering operations)\n",
    "    - this works because there is no barrier at the other sites\n",
    "- no seconds in most of the tt revisions\n",
    "    - on me\n",
    "- is there a policy on removing detections for dam only events with no upstream or downstream events? some inconsistency here; see FBY == 0 and DAM == 1\n",
    "- explore condition for daylight savings time\n",
    "- \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6551110c-e56f-46f5-8ed8-a1526ce795ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmdrt",
   "language": "python",
   "name": "mmdrt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
